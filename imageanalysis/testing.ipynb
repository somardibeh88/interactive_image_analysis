{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3118850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader, EELSLazyLoader\n",
    "from filters import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "fp = '/home/somar/Desktop/own_stuff/cleaning script/example data files/SuperScan-MAADF_2025-02-26T153932.717062_2048x2048_0.ndata1'\n",
    "\n",
    "ds = DataLoader(fp)\n",
    "\n",
    "data = ds.raw_data\n",
    "metadata = ds.raw_metadata\n",
    "\n",
    "len(data), len(metadata)\n",
    "img = data[0]\n",
    "print(img.shape)\n",
    "print(\"Size of the image:\", img.size, img.size/2048)\n",
    "\n",
    "# normalize to 0, 255\n",
    "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "print(img.min(), img.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2950d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold values: [0.0525607  0.15900856]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters\n",
    "from imageanalysis.data_loader import DataLoader\n",
    "# Load your data\n",
    "fp = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/different_sides.h5'\n",
    "ds = DataLoader(fp)\n",
    "data = ds.raw_data\n",
    "metadata = ds.raw_metadata\n",
    "img = data[12]\n",
    "\n",
    "# Compute multi-Otsu thresholds for 3 classes\n",
    "thresholds = filters.threshold_multiotsu(img, classes=3)\n",
    "print(\"Threshold values:\", thresholds)\n",
    "\n",
    "# Digitize (assign each pixel to a class)\n",
    "regions = np.digitize(img, bins=thresholds)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original image\")\n",
    "ax[1].imshow(regions, cmap=\"viridis\")\n",
    "ax[1].set_title(\"Multi-Otsu segmentation\")\n",
    "ax[2].hist(img.ravel(), bins=256)\n",
    "for t in thresholds:\n",
    "    ax[2].axvline(t, color=\"red\", lw=2)\n",
    "ax[2].set_title(\"Histogram + thresholds\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dgfilter(shape, params):\n",
    "    sigma1, sigma2, weight = params\n",
    "    s1 = sigma1 * sigma1\n",
    "    s2 = sigma2 * sigma2\n",
    "\n",
    "    yy_min = -shape[0] // 2\n",
    "    yy_max = shape[0] // 2\n",
    "    xx_min = -shape[1] // 2\n",
    "    xx_max = shape[1] // 2\n",
    "    yy, xx = np.meshgrid(np.linspace(yy_min, yy_max, shape[0]),\n",
    "                         np.linspace(xx_min, xx_max, shape[1]),\n",
    "                         indexing='ij')\n",
    "    rr = np.square(xx / (shape[1] * 0.5)) + np.square(yy / (shape[0] * 0.5))\n",
    "\n",
    "    g1 = np.exp(-0.5 * rr / s1)\n",
    "    g2 = np.exp(-0.5 * rr / s2)\n",
    "    H = g1 - (1.0 - weight) * g2\n",
    "\n",
    "    return g1, g2, H, rr\n",
    "\n",
    "# Parameters from the user\n",
    "sigma1, sigma2, weight = 0.55, 0.15, 0.55\n",
    "shape = (256, 256)\n",
    "\n",
    "g1, g2, H, rr = dgfilter(shape, (sigma1, sigma2, weight))\n",
    "\n",
    "# Radial cross section: take a line through the center\n",
    "center_y, center_x = shape[0] // 2, shape[1] // 2\n",
    "cross_x = g1[center_y, :]\n",
    "cross_y = g2[center_y, :]\n",
    "cross_H = H[center_y, :]\n",
    "axis = np.linspace(-1, 1, shape[1])\n",
    "\n",
    "# Plot 2D maps and cross-sections\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# 2D maps\n",
    "im0 = axs[0, 0].imshow(g1, cmap=\"viridis\")\n",
    "axs[0, 0].set_title(\"Gaussian 1 (σ1=0.55)\")\n",
    "plt.colorbar(im0, ax=axs[0, 0])\n",
    "\n",
    "im1 = axs[0, 1].imshow(g2, cmap=\"viridis\")\n",
    "axs[0, 1].set_title(\"Gaussian 2 (σ2=0.15)\")\n",
    "plt.colorbar(im1, ax=axs[0, 1])\n",
    "\n",
    "im2 = axs[0, 2].imshow(H, cmap=\"viridis\")\n",
    "axs[0, 2].set_title(\"Double Gaussian (Difference)\")\n",
    "plt.colorbar(im2, ax=axs[0, 2])\n",
    "\n",
    "# Cross sections\n",
    "axs[1, 0].plot(axis, cross_x, label=\"σ1=0.55\")\n",
    "axs[1, 0].set_title(\"Cross-section Gaussian 1\")\n",
    "axs[1, 0].set_xlabel(\"Normalized frequency\")\n",
    "axs[1, 0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "axs[1, 1].plot(axis, cross_y, label=\"σ2=0.15\", color=\"orange\")\n",
    "axs[1, 1].set_title(\"Cross-section Gaussian 2\")\n",
    "axs[1, 1].set_xlabel(\"Normalized frequency\")\n",
    "axs[1, 1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "axs[1, 2].plot(axis, cross_x, label=\"G1 (σ1=0.55)\")\n",
    "axs[1, 2].plot(axis, cross_y, label=\"G2 (σ2=0.15)\")\n",
    "axs[1, 2].plot(axis, cross_H, label=\"Double Gaussian\", color=\"red\")\n",
    "axs[1, 2].set_title(\"Cross-section Comparison\")\n",
    "axs[1, 2].set_xlabel(\"Normalized frequency\")\n",
    "axs[1, 2].set_ylabel(\"Amplitude\")\n",
    "axs[1, 2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import cv2\n",
    "from data_loader import DataLoader\n",
    "from filters import improve_contrast\n",
    "from skimage import exposure\n",
    "\n",
    "# Load your data\n",
    "fp = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/different_sides.h5'\n",
    "ds = DataLoader(fp)\n",
    "data = ds.raw_data\n",
    "metadata = ds.raw_metadata\n",
    "img = data[12]\n",
    "\n",
    "# Preprocess the image\n",
    "norm_img = (img - img.min()) / (img.max() - img.min()) * 255\n",
    "norm_img = np.clip(norm_img + 160, 0, 255)\n",
    "data = improve_contrast(norm_img, percentile=3)\n",
    "\n",
    "# Precompute FFT of the data\n",
    "fft_data = np.fft.fftshift(np.fft.fft2(data))\n",
    "\n",
    "# Precompute meshgrid for filter (only once)\n",
    "shape = data.shape\n",
    "center = shape[0]//2\n",
    "axis = np.linspace(-1, 1, shape[1])\n",
    "yy, xx = np.meshgrid(np.linspace(-shape[0]//2, shape[0]//2, shape[0]),\n",
    "                     np.linspace(-shape[1]//2, shape[1]//2, shape[1]),\n",
    "                     indexing='ij')\n",
    "rr = (xx/(shape[1]*0.5))**2 + (yy/(shape[0]*0.5))**2\n",
    "\n",
    "# Precompute normalized uint8 version of data\n",
    "data_uint8 = ((data - data.min()) / (data.max() - data.min()) * 255).astype(np.uint8)\n",
    "\n",
    "# -------------------------------\n",
    "# Setup 2x3 figure\n",
    "# -------------------------------\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10), constrained_layout=True)\n",
    "\n",
    "# Top row: Filter visualization\n",
    "im_filter = axs[0, 0].imshow(np.zeros(shape), cmap=\"viridis\", extent=[-1,1,-1,1])\n",
    "circle1 = Circle((0,0), 0.1, color=\"red\", fill=False, lw=2)\n",
    "circle2 = Circle((0,0), 0.1, color=\"blue\", fill=False, lw=2)\n",
    "axs[0, 0].add_patch(circle1)\n",
    "axs[0, 0].add_patch(circle2)\n",
    "axs[0, 0].legend([circle1, circle2], [\"σ1=0.10\", \"σ2=0.10\"], loc=\"upper right\")\n",
    "axs[0, 0].set_title(\"Double Gaussian (2D)\")\n",
    "plt.colorbar(im_filter, ax=axs[0, 0], fraction=0.046, pad=0.04)\n",
    "\n",
    "line1, = axs[1, 0].plot(axis, np.zeros_like(axis), label=\"Gaussian 1\")\n",
    "line2, = axs[1, 0].plot(axis, np.zeros_like(axis), label=\"Gaussian 2\")\n",
    "line3, = axs[1, 0].plot(axis, np.zeros_like(axis), label=\"Double Gaussian\", color=\"red\")\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].set_title(\"Radial Cross-section\")\n",
    "axs[1, 0].set_xlabel(\"Normalized frequency\")\n",
    "axs[1, 0].set_ylabel(\"Amplitude\")\n",
    "\n",
    "# Original image\n",
    "im_orig = axs[0, 1].imshow(data, cmap=\"viridis\")\n",
    "axs[0, 1].set_title(\"Original Image\")\n",
    "\n",
    "# Filtered image\n",
    "im_out = axs[0, 2].imshow(np.zeros_like(data), cmap=\"viridis\")\n",
    "axs[0, 2].set_title(\"Filtered Image\")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Optimized Double Gaussian Filter Function\n",
    "# -------------------------------\n",
    "def dgfilter_fast(sigma1, sigma2, weight):\n",
    "    s1, s2 = sigma1**2, sigma2**2\n",
    "    g1 = np.exp(-0.5 * rr / s1)\n",
    "    g2 = np.exp(-0.5 * rr / s2)\n",
    "    H = g1 - (1.0 - weight) * g2\n",
    "    return g1, g2, H\n",
    "\n",
    "# -------------------------------\n",
    "# Optimized Update function\n",
    "# -------------------------------\n",
    "def update_dg(sigma1=0.55, sigma2=0.15, weight=0.55):\n",
    "    # Generate filter\n",
    "    g1, g2, H = dgfilter_fast(sigma1, sigma2, weight)\n",
    "\n",
    "    # Apply filter in Fourier domain\n",
    "    filtered_fft = fft_data * H\n",
    "    filtered_image = np.fft.ifft2(np.fft.ifftshift(filtered_fft)).real\n",
    "    \n",
    "    # Normalize the filtered image to 0-255\n",
    "    filtered_min = filtered_image.min()\n",
    "    filtered_max = filtered_image.max()\n",
    "    filtered_range = filtered_max - filtered_min\n",
    "    if filtered_range > 0:\n",
    "        filtered_image = (filtered_image - filtered_min) / filtered_range * 255\n",
    "    filtered_image = filtered_image.astype(np.uint8)\n",
    "\n",
    "    # Otsu thresholding\n",
    "    _, thr_orig = cv2.threshold(data_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, thr_filt = cv2.threshold(filtered_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Update filter visualization\n",
    "    im_filter.set_data(H)\n",
    "    im_filter.set_clim(H.min(), H.max())\n",
    "    # Thresholded images\n",
    "    im_thr_orig = axs[1, 1].imshow(thr_orig, cmap=\"gray\")\n",
    "    axs[1, 1].set_title(\"Otsu Thresholded Original\")\n",
    "\n",
    "    im_thr_filt = axs[1, 2].imshow(thr_filt, cmap=\"gray\")\n",
    "    axs[1, 2].set_title(\"Otsu Thresholded Filtered\")\n",
    "    # Update circles\n",
    "    circle1.set_radius(sigma1)\n",
    "    circle2.set_radius(sigma2)\n",
    "    axs[0, 0].legend([circle1, circle2], \n",
    "                   [f\"σ1={sigma1:.2f}\", f\"σ2={sigma2:.2f}\"], \n",
    "                   loc=\"upper right\")\n",
    "\n",
    "    # Update cross-section\n",
    "    line1.set_ydata(g1[center,:])\n",
    "    line2.set_ydata(g2[center,:])\n",
    "    line3.set_ydata(H[center,:])\n",
    "    axs[1, 0].relim()\n",
    "    axs[1, 0].autoscale_view()\n",
    "\n",
    "    # Update images\n",
    "    im_out.set_data(filtered_image)\n",
    "    im_out.set_clim(filtered_image.min(), filtered_image.max())\n",
    "    im_thr_orig.set_data(thr_orig)\n",
    "    im_thr_filt.set_data(thr_filt)\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# -------------------------------\n",
    "# Interactive sliders\n",
    "# -------------------------------\n",
    "interact(update_dg,\n",
    "         sigma1=FloatSlider(min=0.1, max=1.0, step=0.05, value=0.55),\n",
    "         sigma2=FloatSlider(min=0.05, max=0.5, step=0.05, value=0.15),\n",
    "         weight=FloatSlider(min=0.0, max=1.0, step=0.05, value=0.55))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8016540a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fe16a81c954de4b41424165521653c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2979f17f5454be99ba4c57764837e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.55, description='sigma1', max=1.0, min=0.1, step=0.05), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_dg(sigma1=0.55, sigma2=0.15, weight=0.55)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from ipywidgets import interact, FloatSlider, Output\n",
    "import IPython.display as display\n",
    "\n",
    "# Use widget backend for interactive updates\n",
    "\n",
    "\n",
    "def dgfilter(shape, sigma1, sigma2, weight):\n",
    "    s1, s2 = sigma1**2, sigma2**2\n",
    "    yy, xx = np.meshgrid(np.linspace(-shape[0]//2, shape[0]//2, shape[0]),\n",
    "                         np.linspace(-shape[1]//2, shape[1]//2, shape[1]),\n",
    "                         indexing='ij')\n",
    "    rr = (xx/(shape[1]*0.5))**2 + (yy/(shape[0]*0.5))**2\n",
    "    g1 = np.exp(-0.5 * rr / s1)\n",
    "    g2 = np.exp(-0.5 * rr / s2)\n",
    "    H = g1 - (1.0 - weight) * g2\n",
    "    return g1, g2, H\n",
    "# Create output area and figure\n",
    "out = Output()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Initialize plots\n",
    "shape = (256, 256)\n",
    "center = shape[0]//2\n",
    "axis = np.linspace(-1, 1, shape[1])\n",
    "\n",
    "# Left plot (2D filter)\n",
    "im = axs[0].imshow(np.zeros(shape), cmap=\"viridis\", extent=[-1,1,-1,1])\n",
    "circle1 = Circle((0,0), 0.1, color=\"red\", fill=False, lw=2)\n",
    "circle2 = Circle((0,0), 0.1, color=\"blue\", fill=False, lw=2)\n",
    "axs[0].add_patch(circle1)\n",
    "axs[0].add_patch(circle2)\n",
    "axs[0].legend([circle1, circle2], [\"σ1=0.10\", \"σ2=0.10\"], loc=\"upper right\")\n",
    "plt.colorbar(im, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Right plot (cross-section)\n",
    "line1, = axs[1].plot(axis, np.zeros_like(axis), label=\"Gaussian 1\")\n",
    "line2, = axs[1].plot(axis, np.zeros_like(axis), label=\"Gaussian 2\")\n",
    "line3, = axs[1].plot(axis, np.zeros_like(axis), label=\"Double Gaussian\", color=\"red\")\n",
    "axs[1].legend()\n",
    "axs[1].set_title(\"Radial Cross-section\")\n",
    "axs[1].set_xlabel(\"Normalized frequency\")\n",
    "axs[1].set_ylabel(\"Amplitude\")\n",
    "\n",
    "def update_dg(sigma1=0.55, sigma2=0.15, weight=0.55):\n",
    "    with out:\n",
    "        # Recalculate filter\n",
    "        g1, g2, H = dgfilter(shape, sigma1, sigma2, weight)\n",
    "        \n",
    "        # Update 2D plot\n",
    "        im.set_data(H)\n",
    "        im.set_clim(H.min(), H.max())\n",
    "        \n",
    "        # Update circles\n",
    "        circle1.set_radius(sigma1)\n",
    "        circle2.set_radius(sigma2)\n",
    "        \n",
    "        # Update legend\n",
    "        axs[0].legend([circle1, circle2], \n",
    "                     [f\"σ1={sigma1:.2f}\", f\"σ2={sigma2:.2f}\"], \n",
    "                     loc=\"upper right\")\n",
    "        \n",
    "        # Update cross-section\n",
    "        line1.set_ydata(g1[center,:])\n",
    "        line2.set_ydata(g2[center,:])\n",
    "        line3.set_ydata(H[center,:])\n",
    "        axs[1].relim()\n",
    "        axs[1].autoscale_view()\n",
    "        \n",
    "        # Redraw the figure\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "\n",
    "# Display the output area\n",
    "display.display(out)\n",
    "\n",
    "# Create interactive widget\n",
    "interact(update_dg,\n",
    "         sigma1=FloatSlider(min=0.1, max=1.0, step=0.05, value=0.55),\n",
    "         sigma2=FloatSlider(min=0.05, max=0.5, step=0.05, value=0.15),\n",
    "         weight=FloatSlider(min=0.0, max=1.0, step=0.05, value=0.55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "\n",
    "\n",
    "# Flatten intensities for K-means\n",
    "pixels = img.reshape(-1, 1)\n",
    "\n",
    "# ----------- Step 2: Run K-means -----------\n",
    "kmeans = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
    "labels = kmeans.fit_predict(pixels)\n",
    "centers = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "# Sort centers so c_low < c_high\n",
    "c_low, c_high = np.sort(centers)\n",
    "\n",
    "# ----------- Step 3: Midpoint threshold -----------\n",
    "T_kmeans_mid = (c_low + c_high) / 2\n",
    "\n",
    "# ----------- Step 4: Otsu threshold -----------\n",
    "T_otsu = threshold_otsu(img)\n",
    "\n",
    "# ----------- Step 5: Histogram-minimum threshold -----------\n",
    "hist, bin_edges = np.histogram(img, bins=256)\n",
    "min_idx = np.argmin(hist[np.searchsorted(bin_edges, c_low):np.searchsorted(bin_edges, c_high)])\n",
    "T_hist_min = bin_edges[np.searchsorted(bin_edges, c_low) + min_idx]\n",
    "\n",
    "# ----------- Step 6: Create masks -----------\n",
    "mask_kmeans = labels.reshape(img.shape)\n",
    "mask_midpoint = (img >= T_kmeans_mid).astype(np.uint8)\n",
    "mask_otsu = (img >= T_otsu).astype(np.uint8)\n",
    "mask_hist_min = (img >= T_hist_min).astype(np.uint8)\n",
    "\n",
    "# ----------- Step 7: Misclassification % -----------\n",
    "def misclass_rate(mask, ref):\n",
    "    return 100 * np.sum(mask != ref) / mask.size\n",
    "\n",
    "mis_mid = misclass_rate(mask_midpoint, mask_kmeans)\n",
    "mis_otsu = misclass_rate(mask_otsu, mask_kmeans)\n",
    "mis_hist = misclass_rate(mask_hist_min, mask_kmeans)\n",
    "\n",
    "print(f\"K-means centers: {c_low:.2f}, {c_high:.2f}\")\n",
    "print(f\"Midpoint threshold: {T_kmeans_mid:.2f} -> Misclassification: {mis_mid:.2f}%\")\n",
    "print(f\"Otsu threshold: {T_otsu:.2f} -> Misclassification: {mis_otsu:.2f}%\")\n",
    "print(f\"Histogram-minimum threshold: {T_hist_min:.2f} -> Misclassification: {mis_hist:.2f}%\")\n",
    "\n",
    "# ----------- Step 8: Visual comparison -----------\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axs[0].imshow(mask_kmeans, cmap='gray'); axs[0].set_title(\"K-means Label Mask\")\n",
    "axs[1].imshow(mask_midpoint, cmap='gray'); axs[1].set_title(f\"Midpoint (Err {mis_mid:.1f}%)\")\n",
    "axs[2].imshow(mask_otsu, cmap='gray'); axs[2].set_title(f\"Otsu (Err {mis_otsu:.1f}%)\")\n",
    "axs[3].imshow(mask_hist_min, cmap='gray'); axs[3].set_title(f\"Hist-Min (Err {mis_hist:.1f}%)\")\n",
    "\n",
    "for ax in axs: ax.axis('off')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dgfilter(shape, params):\n",
    "    sigma1, sigma2, weight = params\n",
    "    s1 = sigma1 * sigma1\n",
    "    s2 = sigma2 * sigma2\n",
    "\n",
    "    yy_min = -shape[0] // 2\n",
    "    yy_max = shape[0] // 2\n",
    "    xx_min = -shape[1] // 2\n",
    "    xx_max = shape[1] // 2\n",
    "    yy, xx = np.meshgrid(np.linspace(yy_min, yy_max, shape[0]),\n",
    "                         np.linspace(xx_min, xx_max, shape[1]),\n",
    "                         indexing='ij')\n",
    "    rr = np.square(xx / (shape[1] * 0.5)) + np.square(yy / (shape[0] * 0.5))\n",
    "    return np.exp(-0.5 * rr / s1) - (1.0 - weight) * np.exp(-0.5 * rr / s2)\n",
    "\n",
    "# Parameters to test\n",
    "shapes = (256, 256)\n",
    "parameter_sets = [\n",
    "    (0.65, 0.2, 0.6),   # sigma1 < sigma2, balanced\n",
    "    (0.3, 0.1, 0.5),   # sigma1 > sigma2, balanced\n",
    "    (0.2, 0.4, 0.9),   # strong emphasis on first Gaussian\n",
    "    (0.2, 0.4, 0.1),   # strong emphasis on second Gaussian\n",
    "    (0.2, 0.2, 0.5),   # equal sigmas (degenerate case)\n",
    "]\n",
    "\n",
    "figs = []\n",
    "for i, params in enumerate(parameter_sets):\n",
    "    dg = dgfilter(shapes, params)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(dg, cmap='bwr', extent=[-1, 1, -1, 1])\n",
    "    ax.set_title(f\"σ₁={params[0]}, σ₂={params[1]}, weight={params[2]}\")\n",
    "    ax.set_xlabel(\"Normalized x\")\n",
    "    ax.set_ylabel(\"Normalized y\")\n",
    "    fig.colorbar(ax.images[0], ax=ax)\n",
    "    figs.append(fig)\n",
    "\n",
    "figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider, VBox\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import DataLoader\n",
    "filepath_ndata = '/home/somar/Desktop/own_stuff/cleaning script/example data files/081.ndata1'\n",
    "\n",
    "img = DataLoader(filepath_ndata).raw_data[4]\n",
    "\n",
    "def make_double_gaussian_filter(shape, sigma1, sigma2, weight):\n",
    "    h, w = shape\n",
    "    y, x = np.indices((h, w))\n",
    "    cy, cx = h // 2, w // 2\n",
    "    r2 = (x - cx)**2 + (y - cy)**2\n",
    "\n",
    "    G1 = np.exp(-r2 / (2 * sigma1**2))\n",
    "    G2 = np.exp(-r2 / (2 * sigma2**2))\n",
    "\n",
    "    filter_kernel = G1 - (1 - weight) * G2\n",
    "    return fftshift(filter_kernel)\n",
    "\n",
    "# --- Apply filter ---\n",
    "def apply_filter(img, sigma1, sigma2, weight):\n",
    "    kernel = make_double_gaussian_filter(img.shape, sigma1, sigma2, weight)\n",
    "    f_img = fft2(img)\n",
    "    f_filtered = f_img * kernel\n",
    "    filtered = np.real(ifft2(f_filtered))\n",
    "    return filtered, kernel\n",
    "\n",
    "# --- Interactive visualization ---\n",
    "def interactive_filter(sigma1, sigma2, weight):\n",
    "    filtered, kernel = apply_filter(img, sigma1, sigma2, weight)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    ax[0].imshow(img, cmap='gray')\n",
    "    ax[0].set_title(\"Original\")\n",
    "\n",
    "    ax[1].imshow(filtered, cmap='gray')\n",
    "    ax[1].set_title(f\"Filtered\\n($\\\\sigma_1$={sigma1}, $\\\\sigma_2$={sigma2}, w={weight:.2f})\")\n",
    "\n",
    "    ax[2].imshow(kernel, cmap='viridis')\n",
    "    ax[2].set_title(\"Filter (Freq Domain)\")\n",
    "    fig.colorbar(ax[2].images[0], ax=ax[2])\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Create interactive sliders ---\n",
    "interact(\n",
    "    interactive_filter,\n",
    "    sigma1=FloatSlider(min=1, max=100, step=1, value=20, description='σ1'),\n",
    "    sigma2=FloatSlider(min=1, max=100, step=1, value=40, description='σ2'),\n",
    "    weight=FloatSlider(min=0.0, max=1.0, step=0.05, value=0.5, description='Weight')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9346db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt5\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import cv2\n",
    "font_path = \"/home/somar/.fonts/SourceSansPro-Semibold.otf\" \n",
    "\n",
    "different_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/different_sides.h5'\n",
    "\n",
    "same_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2525/26-03-2025/same_sides.h5'\n",
    "\n",
    "from data_loader import DataLoader\n",
    "img = DataLoader(same_sides_irradiation)\n",
    "\n",
    "\n",
    "image = img.raw_data[24]\n",
    "image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "image = image.astype(np.uint8)\n",
    "image = image[590 : 590+ 100, 305 : 305 + 100]\n",
    "thresh = cv2.inRange(image, 0, 3.1)  # 3.1 becomes 3 anyway\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "valid_contours = [cnt for cnt in contours if 400 <= cv2.contourArea(cnt) < 1e15]  # large upper bound\n",
    "print(f\"Total contours found: {len(valid_contours)}\")\n",
    "\n",
    "contour_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "cv2.drawContours(contour_mask, valid_contours, -1, color=255, thickness=cv2.FILLED)\n",
    "image = image.astype(np.uint8)\n",
    "masked_image = cv2.bitwise_and(image, image, mask=contour_mask)\n",
    "thresh_1_Otsu = cv2.threshold(masked_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(masked_image, cmap='gray')\n",
    "ax[0].set_title('Masked Image')\n",
    "ax[1].imshow(thresh_1_Otsu, cmap='gray')\n",
    "ax[1].set_title('Otsu Thresholding')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import DataLoader\n",
    "\n",
    "# Load image in grayscale\n",
    "img = DataLoader(same_sides_irradiation)\n",
    "img = img.raw_data[24]\n",
    "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "img = img.astype(np.uint8)\n",
    "img = img[590 : 590 + 100, 305 : 305 + 100]\n",
    "\n",
    "# Reshape image to a 2D array of pixels (needed for k-means)\n",
    "pixel_values = img.reshape((-1, 1))\n",
    "pixel_values = np.float32(pixel_values)  # Convert to float32 as required by cv2.kmeans\n",
    "\n",
    "# Define criteria for k-means (max iterations or epsilon)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 0.05)\n",
    "\n",
    "# Number of clusters (2 for binary thresholding)\n",
    "k = 4\n",
    "\n",
    "# Apply k-means clustering\n",
    "_, labels, centers = cv2.kmeans(pixel_values, k, None, criteria, 100, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Convert centers to uint8\n",
    "centers = np.uint8(centers)\n",
    "\n",
    "# Map labels to corresponding center values\n",
    "segmented_data = centers[labels.flatten()]\n",
    "segmented_image = segmented_data.reshape(img.shape)\n",
    "\n",
    "# Corrected thresholding step: flatten thresholded_img before indexing\n",
    "thresholded_img = np.zeros_like(segmented_image).flatten()\n",
    "foreground_cluster = np.argmax(centers)  # cluster with higher intensity\n",
    "thresholded_img[labels.flatten() == foreground_cluster] = 255\n",
    "thresholded_img = thresholded_img.reshape(img.shape)\n",
    "\n",
    "# Show results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Segmented Image (K-means)')\n",
    "plt.imshow(segmented_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Thresholded Image')\n",
    "plt.imshow(thresholded_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "End-to-end pipeline to build a labeled dataset from prior thresholded STEM images,\n",
    "train a lightweight CNN to classify patches as {background, single Pt atom, cluster},\n",
    "and run inference on new images.\n",
    "\n",
    "Usage examples\n",
    "--------------\n",
    "1) Build dataset of patches from images + masks (masks come from your prior thresholding):\n",
    "\n",
    "   python pt_atom_cluster_pipeline.py build \\\n",
    "       --images_dir /path/to/raw_images \\\n",
    "       --masks_dir  /path/to/binary_masks \\\n",
    "       --out_dir    /path/to/patch_dataset \\\n",
    "       --nm_per_pixel 0.05 \\\n",
    "       --pt_apparent_diameter_nm 0.22 \\\n",
    "       --atom_area_tolerance 0.35 \\\n",
    "       --patch_size 32 \\\n",
    "       --train_split 0.8 --val_split 0.1 --test_split 0.1\n",
    "\n",
    "   Notes:\n",
    "     - pt_apparent_diameter_nm is the *apparent* FWHM-like diameter of a single Pt atom in your imaging conditions.\n",
    "       If unknown, start with ~0.18–0.30 nm; refine later by looking at your single-atom area histogram.\n",
    "     - atom_area_tolerance widens the acceptable area band for single atoms (fractional, e.g. 0.35 → ±35%).\n",
    "\n",
    "2) Train the CNN classifier on the generated patches:\n",
    "\n",
    "   python pt_atom_cluster_pipeline.py train \\\n",
    "       --data_dir /path/to/patch_dataset \\\n",
    "       --epochs 40 --batch_size 128 --lr 1e-3 \\\n",
    "       --model_out /path/to/pt_classifier.pt\n",
    "\n",
    "3) Run inference on a new image using candidate proposals from a coarse threshold:\n",
    "\n",
    "   python pt_atom_cluster_pipeline.py infer \\\n",
    "       --image /path/to/new_stem_image.tif \\\n",
    "       --model /path/to/pt_classifier.pt \\\n",
    "       --nm_per_pixel 0.05 \\\n",
    "       --pt_apparent_diameter_nm 0.22 \\\n",
    "       --patch_size 32 \\\n",
    "       --out_vis /path/to/overlay.png\n",
    "\n",
    "Dependencies\n",
    "------------\n",
    "- Python 3.9+\n",
    "- numpy, scipy, opencv-python, scikit-image, matplotlib (optional for visualization)\n",
    "- torch, torchvision\n",
    "\n",
    "File expectations\n",
    "-----------------\n",
    "- images_dir: raw STEM images (8-bit or 16-bit grayscale), readable by OpenCV or imageio.\n",
    "- masks_dir: corresponding binary masks (same filenames) from your prior thresholding.\n",
    "  Foreground = any Pt-related feature; background = everything else.\n",
    "\n",
    "Labeling rule\n",
    "-------------\n",
    "- Connected components are extracted from each mask. For each component, area (px^2) is measured and\n",
    "  compared against an *expected single-atom area band* derived from calibration:\n",
    "\n",
    "   expected_atom_area_px = (pi/4) * (d_px)^2,  with  d_px = pt_apparent_diameter_nm / nm_per_pixel\n",
    "\n",
    "  Single Atom (class 1): area_px in [ (1-τ)*expected_atom_area_px , (1+τ)*expected_atom_area_px ]\n",
    "  Cluster     (class 2): area_px  > (1+τ)*expected_atom_area_px\n",
    "  Background  (class 0): sampled from regions outside any component.\n",
    "\n",
    "- You can later switch to a Feret-diameter-based rule if preferred.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import measure\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "try:\n",
    "    from torchvision import transforms\n",
    "except Exception:\n",
    "    transforms = None  # falls back to minimal augmentation\n",
    "\n",
    "# -----------------------------\n",
    "# Utility helpers\n",
    "# -----------------------------\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def read_gray(path: Path) -> np.ndarray:\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Cannot read image: {path}\")\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Normalize to uint8 for stability\n",
    "    if img.dtype != np.uint8:\n",
    "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def compute_expected_atom_area_px(nm_per_pixel: float, pt_apparent_diameter_nm: float) -> float:\n",
    "    d_px = pt_apparent_diameter_nm / nm_per_pixel\n",
    "    return (math.pi / 4.0) * (d_px ** 2)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset building from masks\n",
    "# -----------------------------\n",
    "\n",
    "def extract_components(mask: np.ndarray) -> List[np.ndarray]:\n",
    "    # Ensure binary\n",
    "    m = (mask > 0).astype(np.uint8)\n",
    "    labeled = measure.label(m, connectivity=2)\n",
    "    props = measure.regionprops(labeled)\n",
    "    contours = []\n",
    "    for pr in props:\n",
    "        coords = pr.coords  # (N,2) row,col\n",
    "        # Create a contour via convex hull on pixel coordinates for robustness\n",
    "        pts = np.flip(coords, axis=1).astype(np.int32)  # to (x,y)\n",
    "        if pts.shape[0] < 3:\n",
    "            continue\n",
    "        hull = cv2.convexHull(pts)\n",
    "        contours.append(hull)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def bbox_from_contour(cnt: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    return x, y, w, h\n",
    "\n",
    "\n",
    "def crop_patch(img: np.ndarray, cx: int, cy: int, patch_size: int) -> np.ndarray:\n",
    "    r = patch_size // 2\n",
    "    h, w = img.shape\n",
    "    x0, y0 = max(0, cx - r), max(0, cy - r)\n",
    "    x1, y1 = min(w, cx + r), min(h, cy + r)\n",
    "    patch = np.zeros((patch_size, patch_size), dtype=img.dtype)\n",
    "    patch[y0 - (cy - r): y1 - (cy - r), x0 - (cx - r): x1 - (cx - r)] = img[y0:y1, x0:x1]\n",
    "    return patch\n",
    "\n",
    "\n",
    "def build_patches_for_image(\n",
    "    img_path: Path,\n",
    "    mask_path: Path,\n",
    "    out_dir: Path,\n",
    "    nm_per_pixel: float,\n",
    "    pt_apparent_diameter_nm: float,\n",
    "    atom_area_tolerance: float,\n",
    "    patch_size: int,\n",
    "    max_background_per_image: int = 200,\n",
    "):\n",
    "    img = read_gray(img_path)\n",
    "    mask = read_gray(mask_path)\n",
    "\n",
    "    expected_atom_area_px = compute_expected_atom_area_px(nm_per_pixel, pt_apparent_diameter_nm)\n",
    "    lower = (1.0 - atom_area_tolerance) * expected_atom_area_px\n",
    "    upper = (1.0 + atom_area_tolerance) * expected_atom_area_px\n",
    "\n",
    "    # Connected components from mask\n",
    "    cnts = extract_components(mask)\n",
    "\n",
    "    # Prepare class folders\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for cls in [\"0_background\", \"1_single\", \"2_cluster\"]:\n",
    "            ensure_dir(out_dir / split / cls)\n",
    "\n",
    "    # Random split per image to keep simplicity; for reproducibility, fix seed\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    # Positive samples from components\n",
    "    h, w = img.shape\n",
    "    bg_mask = (mask == 0)\n",
    "    bg_coords = np.column_stack(np.where(bg_mask))  # (y,x)\n",
    "\n",
    "    def choose_split():\n",
    "        r = rng.rand()\n",
    "        if r < 0.8:\n",
    "            return \"train\"\n",
    "        elif r < 0.9:\n",
    "            return \"val\"\n",
    "        else:\n",
    "            return \"test\"\n",
    "\n",
    "    idx_c = 0\n",
    "    for cnt in cnts:\n",
    "        area_px = cv2.contourArea(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])  # x\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])  # y\n",
    "        patch = crop_patch(img, cx, cy, patch_size)\n",
    "\n",
    "        if lower <= area_px <= upper:\n",
    "            cls = \"1_single\"\n",
    "        elif area_px > upper:\n",
    "            cls = \"2_cluster\"\n",
    "        else:\n",
    "            # very small components likely noise → skip\n",
    "            continue\n",
    "\n",
    "        split = choose_split()\n",
    "        out_path = out_dir / split / cls / f\"{img_path.stem}_{idx_c:05d}.png\"\n",
    "        cv2.imwrite(str(out_path), patch)\n",
    "        idx_c += 1\n",
    "\n",
    "    # Background patches sampled uniformly\n",
    "    bg_count = 0\n",
    "    r = patch_size // 2\n",
    "    while bg_count < max_background_per_image and bg_coords.shape[0] > 0:\n",
    "        yi, xi = bg_coords[rng.randint(0, bg_coords.shape[0])]\n",
    "        # ensure a margin away from any foreground (dilate mask and test)\n",
    "        if yi < r or xi < r or yi + r >= h or xi + r >= w:\n",
    "            continue\n",
    "        patch = crop_patch(img, xi, yi, patch_size)\n",
    "        split = choose_split()\n",
    "        out_path = out_dir / split / \"0_background\" / f\"{img_path.stem}_bg_{bg_count:05d}.png\"\n",
    "        cv2.imwrite(str(out_path), patch)\n",
    "        bg_count += 1\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Torch dataset for patches\n",
    "# -----------------------------\n",
    "\n",
    "class PatchFolder(Dataset):\n",
    "    def __init__(self, root: Path, split: str, patch_size: int = 32):\n",
    "        self.root = Path(root)\n",
    "        self.split = split\n",
    "        self.patch_size = patch_size\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {\"0_background\": 0, \"1_single\": 1, \"2_cluster\": 2}\n",
    "        for cls in self.class_to_idx.keys():\n",
    "            cls_dir = self.root / split / cls\n",
    "            if not cls_dir.exists():\n",
    "                continue\n",
    "            for p in cls_dir.glob(\"*.png\"):\n",
    "                self.samples.append((p, self.class_to_idx[cls]))\n",
    "        self.transform = self._build_transform()\n",
    "\n",
    "    def _build_transform(self):\n",
    "        ops = []\n",
    "        # To tensor\n",
    "        ops.append(lambda x: torch.from_numpy(x[None, ...].astype(np.float32) / 255.0))\n",
    "        # Augmentations (if torchvision not available, keep minimal)\n",
    "        def _aug(t):\n",
    "            # Random flips\n",
    "            if random.random() < 0.5:\n",
    "                t = torch.flip(t, dims=[2])  # horizontal\n",
    "            if random.random() < 0.5:\n",
    "                t = torch.flip(t, dims=[1])  # vertical\n",
    "            # Small random rotation by multiples of 90 deg\n",
    "            k = random.randint(0, 3)\n",
    "            t = torch.rot90(t, k, dims=[1, 2])\n",
    "            # Add slight Gaussian noise\n",
    "            if random.random() < 0.5:\n",
    "                t = t + 0.02 * torch.randn_like(t)\n",
    "            return torch.clamp(t, 0.0, 1.0)\n",
    "        return _aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, y = self.samples[idx]\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(p)\n",
    "        if img.shape != (self.patch_size, self.patch_size):\n",
    "            img = cv2.resize(img, (self.patch_size, self.patch_size), interpolation=cv2.INTER_AREA)\n",
    "        x = img.astype(np.float32)\n",
    "        x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "\n",
    "class PtClassifier(nn.Module):\n",
    "    def __init__(self, patch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        # compute flattened size after two pools (patch_size/4)\n",
    "        feat_side = patch_size // 4\n",
    "        self.fc1 = nn.Linear(64 * feat_side * feat_side, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training / Evaluation\n",
    "# -----------------------------\n",
    "\n",
    "def train_model(data_dir: Path, patch_size: int, epochs: int, batch_size: int, lr: float, model_out: Path, device: str = None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_ds = PatchFolder(data_dir, \"train\", patch_size)\n",
    "    val_ds = PatchFolder(data_dir, \"val\", patch_size)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = PtClassifier(patch_size).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_loss = running_loss / max(1, total)\n",
    "        train_acc = correct / max(1, total)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        v_correct, v_total = 0, 0\n",
    "        v_loss_accum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = x.to(device)\n",
    "                y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                v_loss_accum += loss.item() * x.size(0)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                v_correct += (pred == y).sum().item()\n",
    "                v_total += y.size(0)\n",
    "        val_loss = v_loss_accum / max(1, v_total)\n",
    "        val_acc = v_correct / max(1, v_total)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} | train loss {train_loss:.4f} acc {train_acc:.3f} | val loss {val_loss:.4f} acc {val_acc:.3f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'patch_size': patch_size,\n",
    "            }, str(model_out))\n",
    "            print(f\"Saved best model → {model_out}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Inference on full image\n",
    "# -----------------------------\n",
    "\n",
    "def softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:\n",
    "    e = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def infer_on_image(image_path: Path, model_path: Path, nm_per_pixel: float, pt_apparent_diameter_nm: float, patch_size: int, out_vis: Path = None, device: str = None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ckpt = torch.load(str(model_path), map_location=device)\n",
    "    model = PtClassifier(patch_size=ckpt.get('patch_size', patch_size))\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.to(device).eval()\n",
    "\n",
    "    img = read_gray(image_path)\n",
    "\n",
    "    # Candidate proposals from coarse threshold: use adaptive or Otsu\n",
    "    thr_val, thr = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thr = thr.astype(np.uint8)\n",
    "    cnts, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    expected_atom_area_px = compute_expected_atom_area_px(nm_per_pixel, pt_apparent_diameter_nm)\n",
    "\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    results = []\n",
    "\n",
    "    for cnt in cnts:\n",
    "        area_px = cv2.contourArea(cnt)\n",
    "        if area_px < 2:  # discard tiny noise\n",
    "            continue\n",
    "        M = cv2.moments(cnt)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])  # x\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])  # y\n",
    "        patch = crop_patch(img, cx, cy, patch_size)\n",
    "        x = torch.from_numpy(patch[None, None, ...].astype(np.float32) / 255.0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "            pred = int(np.argmax(probs))\n",
    "        results.append({\n",
    "            'cx': cx, 'cy': cy,\n",
    "            'area_px': float(area_px),\n",
    "            'pred': pred,\n",
    "            'probs': probs.tolist(),\n",
    "        })\n",
    "        # draw\n",
    "        color = (0, 200, 0) if pred == 1 else ((0, 0, 220) if pred == 2 else (200, 200, 200))\n",
    "        cv2.circle(vis, (cx, cy), 3, color, -1)\n",
    "\n",
    "    if out_vis is not None:\n",
    "        cv2.imwrite(str(out_vis), vis)\n",
    "        print(f\"Saved visualization → {out_vis}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# CLI\n",
    "# -----------------------------\n",
    "\n",
    "def cmd_build(args):\n",
    "    images = sorted(Path(args.images_dir).glob(\"*\"))\n",
    "    masks = sorted(Path(args.masks_dir).glob(\"*\"))\n",
    "    img_map = {p.stem: p for p in images}\n",
    "    msk_map = {p.stem: p for p in masks}\n",
    "\n",
    "    common = sorted(set(img_map.keys()) & set(msk_map.keys()))\n",
    "    if not common:\n",
    "        raise RuntimeError(\"No matching filenames between images_dir and masks_dir (stems must match).\")\n",
    "\n",
    "    out_dir = Path(args.out_dir)\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    for stem in common:\n",
    "        build_patches_for_image(\n",
    "            img_map[stem], msk_map[stem], out_dir,\n",
    "            nm_per_pixel=args.nm_per_pixel,\n",
    "            pt_apparent_diameter_nm=args.pt_apparent_diameter_nm,\n",
    "            atom_area_tolerance=args.atom_area_tolerance,\n",
    "            patch_size=args.patch_size,\n",
    "            max_background_per_image=args.max_background_per_image,\n",
    "        )\n",
    "    print(\"Dataset build complete.\")\n",
    "\n",
    "\n",
    "def cmd_train(args):\n",
    "    train_model(\n",
    "        data_dir=Path(args.data_dir),\n",
    "        patch_size=args.patch_size,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        lr=args.lr,\n",
    "        model_out=Path(args.model_out),\n",
    "        device=args.device,\n",
    "    )\n",
    "\n",
    "\n",
    "def cmd_infer(args):\n",
    "    results = infer_on_image(\n",
    "        image_path=Path(args.image),\n",
    "        model_path=Path(args.model),\n",
    "        nm_per_pixel=args.nm_per_pixel,\n",
    "        pt_apparent_diameter_nm=args.pt_apparent_diameter_nm,\n",
    "        patch_size=args.patch_size,\n",
    "        out_vis=Path(args.out_vis) if args.out_vis else None,\n",
    "        device=args.device,\n",
    "    )\n",
    "    # Print a concise summary\n",
    "    counts = {0: 0, 1: 0, 2: 0}\n",
    "    for r in results:\n",
    "        counts[r['pred']] += 1\n",
    "    print(f\"Detections — background proposals: {counts[0]}, single atoms: {counts[1]}, clusters: {counts[2]}\")\n",
    "\n",
    "\n",
    "def build_parser():\n",
    "    p = argparse.ArgumentParser(description=\"Pt atom vs cluster dataset builder and CNN trainer\")\n",
    "    sub = p.add_subparsers(dest=\"cmd\", required=True)\n",
    "\n",
    "    pb = sub.add_parser(\"build\", help=\"Build patch dataset from images and masks\")\n",
    "    pb.add_argument(\"--images_dir\", type=str, required=True)\n",
    "    pb.add_argument(\"--masks_dir\", type=str, required=True)\n",
    "    pb.add_argument(\"--out_dir\", type=str, required=True)\n",
    "    pb.add_argument(\"--nm_per_pixel\", type=float, required=True, help=\"Calibration in nm/pixel\")\n",
    "    pb.add_argument(\"--pt_apparent_diameter_nm\", type=float, required=True, help=\"Apparent Pt atom diameter (nm)\")\n",
    "    pb.add_argument(\"--atom_area_tolerance\", type=float, default=0.35, help=\"Fractional tolerance around expected atom area (e.g., 0.35 → ±35%)\")\n",
    "    pb.add_argument(\"--patch_size\", type=int, default=32)\n",
    "    pb.add_argument(\"--max_background_per_image\", type=int, default=200)\n",
    "    pb.set_defaults(func=cmd_build)\n",
    "\n",
    "    pt = sub.add_parser(\"train\", help=\"Train CNN on patch dataset\")\n",
    "    pt.add_argument(\"--data_dir\", type=str, required=True)\n",
    "    pt.add_argument(\"--epochs\", type=int, default=40)\n",
    "    pt.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    pt.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    pt.add_argument(\"--patch_size\", type=int, default=32)\n",
    "    pt.add_argument(\"--model_out\", type=str, required=True)\n",
    "    pt.add_argument(\"--device\", type=str, default=None, help=\"cuda | cpu (auto if not set)\")\n",
    "    pt.set_defaults(func=cmd_train)\n",
    "\n",
    "    pi = sub.add_parser(\"infer\", help=\"Run inference on a full image\")\n",
    "    pi.add_argument(\"--image\", type=str, required=True)\n",
    "    pi.add_argument(\"--model\", type=str, required=True)\n",
    "    pi.add_argument(\"--nm_per_pixel\", type=float, required=True)\n",
    "    pi.add_argument(\"--pt_apparent_diameter_nm\", type=float, required=True)\n",
    "    pi.add_argument(\"--patch_size\", type=int, default=32)\n",
    "    pi.add_argument(\"--out_vis\", type=str, default=None)\n",
    "    pi.add_argument(\"--device\", type=str, default=None)\n",
    "    pi.set_defaults(func=cmd_infer)\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    argv = argv or sys.argv[1:]\n",
    "    parser = build_parser()\n",
    "    args = parser.parse_args(argv)\n",
    "    args.func(args)\n",
    "\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
