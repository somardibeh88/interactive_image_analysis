{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b841d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gc\n",
    "# import json\n",
    "# import h5py\n",
    "# import joblib\n",
    "# import zipfile\n",
    "# import tifffile\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import ndimage\n",
    "\n",
    "# from filters import fft, ifft, dgfilter, double_gaussian\n",
    "\n",
    "# class MetadataMethods:\n",
    "#     def get_metadata(self, target_key, data=None):\n",
    "#         \"\"\"This method gets all the values of a certain target key in the metadata json file.\"\"\"\n",
    "#         extracted_values = []\n",
    "#         if data is None:\n",
    "#             data = self._get_full_metadata()\n",
    "#         if isinstance(data, dict):\n",
    "#             if target_key in data and data[target_key] is not None:\n",
    "#                 value_to_extract = data.get(target_key)\n",
    "#                 extracted_values.append(value_to_extract)\n",
    "#             for key, value in data.items():\n",
    "#                 if isinstance(value, (list, dict)):\n",
    "#                     extracted_values.extend(self.get_metadata(target_key, value))\n",
    "#         elif isinstance(data, list):\n",
    "#             for item in data:\n",
    "#                 extracted_values.extend(self.get_metadata(target_key, item))\n",
    "        \n",
    "#         if len(extracted_values) == 1 and isinstance(extracted_values[0], (list)):\n",
    "#             return extracted_values[0]\n",
    "#         return extracted_values\n",
    "\n",
    "#     def get_specific_metadata(self, target_key, required_keys=None, data=None, under_required_keys=False):\n",
    "#         \"\"\"\n",
    "#         This method gets specific metadata based on a condition that the target key is extracted only \n",
    "#         when under specific required keys in the nested dictionaries.\n",
    "#         \"\"\"\n",
    "#         if data is None:\n",
    "#             data = self._get_full_metadata()\n",
    "#         if required_keys is None:\n",
    "#             extracted_values = self.get_metadata(target_key, data)\n",
    "#         else:\n",
    "#             extracted_values = []\n",
    "#             if isinstance(data, dict):\n",
    "#                 for key, value in data.items():\n",
    "#                     if key in required_keys:\n",
    "#                         if isinstance(value, dict):\n",
    "#                             extracted_values.extend(self.get_specific_metadata(target_key, required_keys, value, True))\n",
    "#                         elif isinstance(value, list):\n",
    "#                             for item in value:\n",
    "#                                 extracted_values.extend(self.get_specific_metadata(target_key, required_keys, item, True))\n",
    "#                     elif under_required_keys and key == target_key:\n",
    "#                         extracted_values.append(value)\n",
    "#                     else:\n",
    "#                         if isinstance(value, (dict, list)):\n",
    "#                             extracted_values.extend(self.get_specific_metadata(target_key, required_keys, value, under_required_keys))\n",
    "#             elif isinstance(data, list):\n",
    "#                 for item in data:\n",
    "#                     extracted_values.extend(self.get_specific_metadata(target_key, required_keys, item, under_required_keys))\n",
    "\n",
    "#         if len(extracted_values) == 1 and isinstance(extracted_values[0], (list)):\n",
    "#             return extracted_values[0]\n",
    "#         return extracted_values\n",
    "    \n",
    "#     def _get_full_metadata(self):\n",
    "#         \"\"\"Get full metadata structure - to be implemented by subclasses\"\"\"\n",
    "#         return []\n",
    "\n",
    "# class UnifiedLoader:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.file_path = file_path\n",
    "#         self.format = None\n",
    "#         self.raw_data = None\n",
    "#         self.raw_metadata = None\n",
    "#         self._determine_format()\n",
    "#         self._load_data()\n",
    "        \n",
    "#     def _determine_format(self):\n",
    "#         \"\"\"Determine file format based on extension\"\"\"\n",
    "#         if self.file_path.endswith('.h5'):\n",
    "#             self.format = 'h5'\n",
    "#         elif self.file_path.endswith(('.tif', '.tiff')):\n",
    "#             self.format = 'tiff'\n",
    "#         elif self.file_path.endswith(('.ndata1', '.ndata')):\n",
    "#             self.format = 'ndata'\n",
    "#         elif self.file_path.endswith('.pkl'):\n",
    "#             self.format = 'pkl'\n",
    "#         else:\n",
    "#             raise ValueError(f'Unsupported file format: {self.file_path}')\n",
    "    \n",
    "#     def _load_data(self):\n",
    "#         \"\"\"Load data based on file format\"\"\"\n",
    "#         if self.format == 'h5':\n",
    "#             self._load_h5()\n",
    "#         elif self.format == 'tiff':\n",
    "#             self._load_tiff()\n",
    "#         elif self.format == 'ndata':\n",
    "#             self._load_ndata()\n",
    "#         elif self.format == 'pkl':\n",
    "#             self._load_pkl()\n",
    "        \n",
    "#     def _load_h5(self):\n",
    "#         \"\"\"Lazy loader for HDF5 files (EELS or standard image stack)\"\"\"\n",
    "#         self.h5_file = h5py.File(self.file_path, 'r')\n",
    "        \n",
    "#         if 'pairs' in self.h5_file:\n",
    "#             # EELS structure detected\n",
    "#             class PairLoader(MetadataMethods):\n",
    "#                 def __init__(self, h5_file, key):\n",
    "#                     self.h5_file = h5_file\n",
    "#                     self.key = key\n",
    "#                     self.pairs = sorted(h5_file['pairs'].keys())\n",
    "                \n",
    "#                 def __getitem__(self, index):\n",
    "#                     pair_group = self.h5_file['pairs'][self.pairs[index]]\n",
    "#                     item = pair_group[self.key]\n",
    "#                     if self.key.endswith('metadata'):\n",
    "#                         return json.loads(item.asstr()[()])\n",
    "#                     return item[:]\n",
    "                \n",
    "#                 def __len__(self):\n",
    "#                     return len(self.pairs)\n",
    "                \n",
    "#                 def _get_full_metadata(self):\n",
    "#                     return [self[i] for i in range(len(self))]\n",
    "            \n",
    "#             self.raw_data = PairLoader(self.h5_file, 'image')\n",
    "#             self.raw_metadata = PairLoader(self.h5_file, 'image_metadata')\n",
    "\n",
    "#         elif 'images' in self.h5_file and 'metadata' in self.h5_file:\n",
    "#             # Standard image stack with metadata\n",
    "#             class H5ImageLoader:\n",
    "#                 def __init__(self, h5_file):\n",
    "#                     self.group = h5_file['images']\n",
    "#                 def __getitem__(self, index):\n",
    "#                     return self.group[f\"image_{index:04d}\"][:]\n",
    "#                 def __len__(self):\n",
    "#                     return len(self.group)\n",
    "\n",
    "#             class H5MetadataLoader(MetadataMethods):\n",
    "#                 def __init__(self, h5_file):\n",
    "#                     self.group = h5_file['metadata']\n",
    "#                     # Extract keys and sort by index\n",
    "#                     self.keys = sorted(self.group.keys(), key=lambda x: int(x.split('_')[-1]))\n",
    "                \n",
    "#                 def __getitem__(self, index):\n",
    "#                     if isinstance(index, int):\n",
    "#                         key = self.keys[index]\n",
    "#                     elif isinstance(index, str):\n",
    "#                         key = index\n",
    "#                     else:\n",
    "#                         raise TypeError(\"Index must be int or str\")\n",
    "#                     return json.loads(self.group[key].asstr()[()])\n",
    "                \n",
    "#                 def __len__(self):\n",
    "#                     return len(self.group)\n",
    "                \n",
    "#                 def _get_full_metadata(self):\n",
    "#                     return [self[i] for i in range(len(self))]\n",
    "            \n",
    "#             self.raw_data = H5ImageLoader(self.h5_file)\n",
    "#             self.raw_metadata = H5MetadataLoader(self.h5_file)\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\"Unrecognized HDF5 structure: neither EELS nor image/metadata group found.\")\n",
    "\n",
    "#     def _load_tiff(self):\n",
    "#         \"\"\"Lazy loader for TIFF files\"\"\"\n",
    "#         self.tiff_file = tifffile.TiffFile(self.file_path)\n",
    "        \n",
    "#         # Create lazy accessors for images and metadata\n",
    "#         class TiffImageLoader:\n",
    "#             def __init__(self, tiff_file):\n",
    "#                 self.tiff_file = tiff_file\n",
    "                \n",
    "#             def __getitem__(self, index):\n",
    "#                 return self.tiff_file.pages[index].asarray()\n",
    "            \n",
    "#             def __len__(self):\n",
    "#                 return len(self.tiff_file.pages)\n",
    "        \n",
    "#         class TiffMetadataLoader(MetadataMethods):\n",
    "#             def __init__(self, tiff_file):\n",
    "#                 self.tiff_file = tiff_file\n",
    "                \n",
    "#             def __getitem__(self, index):\n",
    "#                 try:\n",
    "#                     desc = self.tiff_file.pages[index].tags['ImageDescription'].value\n",
    "#                     if 'nion.1=' in desc:\n",
    "#                         json_str = desc.split('nion.1=')[1]\n",
    "#                         return json.loads(json_str)\n",
    "#                     return json.loads(desc)\n",
    "#                 except (KeyError, json.JSONDecodeError):\n",
    "#                     return {}\n",
    "            \n",
    "#             def __len__(self):\n",
    "#                 return len(self.tiff_file.pages)\n",
    "            \n",
    "#             def _get_full_metadata(self):\n",
    "#                 return [self[i] for i in range(len(self))]\n",
    "        \n",
    "#         self.raw_data = TiffImageLoader(self.tiff_file)\n",
    "#         self.raw_metadata = TiffMetadataLoader(self.tiff_file)\n",
    "    \n",
    "#     def _load_ndata(self):\n",
    "#         \"\"\"Lazy loader for NDATA files\"\"\"\n",
    "#         self.zip_file = zipfile.ZipFile(self.file_path, 'r')\n",
    "#         self._ndata_data = None\n",
    "#         self._ndata_metadata = None\n",
    "        \n",
    "#         # Create lazy accessors for images and metadata\n",
    "#         class NdataImageLoader:\n",
    "#             def __init__(self, zip_file):\n",
    "#                 self.zip_file = zip_file\n",
    "#                 self._data = None\n",
    "                \n",
    "#             def __getitem__(self, index):\n",
    "#                 if self._data is None:\n",
    "#                     with self.zip_file.open('data.npy') as f:\n",
    "#                         self._data = np.load(f)\n",
    "#                 return self._data[index]\n",
    "            \n",
    "#             def __len__(self):\n",
    "#                 if self._data is not None:\n",
    "#                     return len(self._data)\n",
    "#                 with self.zip_file.open('data.npy') as f:\n",
    "#                     return np.load(f).shape[0]\n",
    "        \n",
    "#         class NdataMetadataLoader(MetadataMethods):\n",
    "#             def __init__(self, zip_file):\n",
    "#                 self.zip_file = zip_file\n",
    "#                 self._metadata = None\n",
    "                \n",
    "#             def __getitem__(self, index):\n",
    "#                 if self._metadata is None:\n",
    "#                     with self.zip_file.open('metadata.json') as f:\n",
    "#                         self._metadata = json.load(f)\n",
    "#                 return self._metadata\n",
    "            \n",
    "#             def __len__(self):\n",
    "#                 return 1  # Single metadata for entire sequence\n",
    "                \n",
    "#             def _get_full_metadata(self):\n",
    "#                 return self[0]\n",
    "        \n",
    "#         self.raw_data = NdataImageLoader(self.zip_file)\n",
    "#         self.raw_metadata = NdataMetadataLoader(self.zip_file)\n",
    "    \n",
    "#     def _load_pkl(self):\n",
    "#         \"\"\"Loader for PKL files\"\"\"\n",
    "#         data = joblib.load(self.file_path)\n",
    "        \n",
    "#         if 'stack' in self.file_path:\n",
    "#             # Image stack pickle\n",
    "#             self.raw_data = data\n",
    "#             self.raw_metadata = {}\n",
    "#         elif 'metadata' in self.file_path:\n",
    "#             # Metadata pickle\n",
    "#             class PklMetadataLoader(MetadataMethods):\n",
    "#                 def __init__(self, data):\n",
    "#                     self.data = data\n",
    "                \n",
    "#                 def __getitem__(self, index):\n",
    "#                     return self.data\n",
    "                \n",
    "#                 def __len__(self):\n",
    "#                     return 1\n",
    "                \n",
    "#                 def _get_full_metadata(self):\n",
    "#                     return self.data\n",
    "                    \n",
    "#             self.raw_metadata = PklMetadataLoader(data)\n",
    "#             self.raw_data = np.empty(0)  # Empty placeholder\n",
    "#         else:\n",
    "#             raise ValueError(\"Unsupported pickle file content\")\n",
    "    \n",
    "#     def close(self):\n",
    "#         \"\"\"Clean up resources\"\"\"\n",
    "#         if self.format == 'h5' and hasattr(self, 'h5_file'):\n",
    "#             self.h5_file.close()\n",
    "#         elif self.format == 'tiff' and hasattr(self, 'tiff_file'):\n",
    "#             self.tiff_file.close()\n",
    "#         elif self.format == 'ndata' and hasattr(self, 'zip_file'):\n",
    "#             self.zip_file.close()\n",
    "    \n",
    "#     def __del__(self):\n",
    "#         \"\"\"Destructor to ensure resources are freed\"\"\"\n",
    "#         self.close()\n",
    "\n",
    "# class ImageSequence:\n",
    "#     def __init__(self, file_path):\n",
    "#         self.file_path = file_path\n",
    "#         self.loader = UnifiedLoader(file_path)\n",
    "        \n",
    "#         # Access data and metadata through unified interface\n",
    "#         self.raw_data = self.loader.raw_data\n",
    "#         self.raw_metadata = self.loader.raw_metadata\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.raw_data[index]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.raw_data)\n",
    "    \n",
    "#     def get_frame(self, index):\n",
    "#         return self[index]\n",
    "\n",
    "#     def get_metadata(self, target_key, data=None):\n",
    "#         return self.raw_metadata.get_metadata(target_key, data)\n",
    "    \n",
    "#     def get_specific_metadata(self, target_key, required_keys=None, data=None, under_required_keys=False):\n",
    "#         return self.raw_metadata.get_specific_metadata(\n",
    "#             target_key, required_keys, data, under_required_keys\n",
    "#         )\n",
    "    \n",
    "#     def get_metadata_item(self, key):\n",
    "#         \"\"\"Get metadata item by key (for HDF5 metadata access)\"\"\"\n",
    "#         return self.raw_metadata[key]\n",
    "\n",
    "# class ProcessedLazyLoader:\n",
    "#     \"\"\"Lazy loader that applies processing on the fly\"\"\"\n",
    "#     def __init__(self, base_loader, filter_function):\n",
    "#         self.base_loader = base_loader\n",
    "#         self.filter_function = filter_function\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         img = self.base_loader[index]\n",
    "#         return self.filter_function(img)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.base_loader)\n",
    "\n",
    "# class H5ImageSequence:\n",
    "#     def __init__(self, h5_file):\n",
    "#         self.h5_file = h5_file\n",
    "#         self._file = None\n",
    "#         self._is_eels = False\n",
    "#         self._pair_keys = []\n",
    "#         self._open_file()  # Open file immediately on instantiation\n",
    "        \n",
    "#     def _open_file(self):\n",
    "#         \"\"\"Open the HDF5 file and determine its structure\"\"\"\n",
    "#         if self._file is None:\n",
    "#             self._file = h5py.File(self.h5_file, 'r')\n",
    "            \n",
    "#             # Determine file type\n",
    "#             if 'pairs' in self._file:\n",
    "#                 self._is_eels = True\n",
    "#                 self._pair_keys = sorted(list(self._file['pairs'].keys()))\n",
    "#             elif 'images' in self._file:\n",
    "#                 self._is_eels = False\n",
    "#             else:\n",
    "#                 raise ValueError(\"Invalid HDF5 structure - missing 'pairs' or 'images' group\")\n",
    "    \n",
    "#     def close(self):\n",
    "#         \"\"\"Explicitly close the file when finished\"\"\"\n",
    "#         if self._file:\n",
    "#             self._file.close()\n",
    "#             self._file = None\n",
    "            \n",
    "#     def __enter__(self):\n",
    "#         # File is already open, just return self\n",
    "#         return self\n",
    "    \n",
    "#     def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "#         self.close()\n",
    "        \n",
    "#     def __del__(self):\n",
    "#         \"\"\"Destructor ensures file is closed when object is garbage collected\"\"\"\n",
    "#         self.close()\n",
    "        \n",
    "#     @property\n",
    "#     def is_eels(self):\n",
    "#         return self._is_eels\n",
    "    \n",
    "#     @property\n",
    "#     def raw_data(self):\n",
    "#         if self._is_eels:\n",
    "#             return EELSLazyLoader(self._file, 'image')\n",
    "#         else:\n",
    "#             return ImageLazyLoader(self._file, 'images')\n",
    "    \n",
    "#     @property\n",
    "#     def raw_metadata(self):\n",
    "#         if self._is_eels:\n",
    "#             return EELSLazyLoader(self._file, 'image_metadata')\n",
    "#         else:\n",
    "#             return MetadataLazyLoader(self._file)\n",
    "    \n",
    "#     def get_spectrum(self, index):\n",
    "#         \"\"\"Get spectrum data for EELS pair (only for EELS files)\"\"\"\n",
    "#         if not self._is_eels:\n",
    "#             raise RuntimeError(\"Spectrum data only available for EELS files\")\n",
    "#         return EELSLazyLoader(self._file, 'spectrum')[index]\n",
    "    \n",
    "#     def get_spectrum_metadata(self, index):\n",
    "#         \"\"\"Get spectrum metadata for EELS pair (only for EELS files)\"\"\"\n",
    "#         if not self._is_eels:\n",
    "#             raise RuntimeError(\"Spectrum metadata only available for EELS files\")\n",
    "#         return EELSLazyLoader(self._file, 'spectrum_metadata')[index]\n",
    "    \n",
    "#     def get_original_filenames(self, index):\n",
    "#         \"\"\"Get original filenames for a pair (only for EELS files)\"\"\"\n",
    "#         if not self._is_eels:\n",
    "#             raise RuntimeError(\"Original filenames only available for EELS files\")\n",
    "#         pair_group = self._file['pairs'][self._pair_keys[index]]\n",
    "#         return {\n",
    "#             'point_spectrum': pair_group.attrs.get('point_spectrum_file', ''),\n",
    "#             'image': pair_group.attrs.get('image_file', '')\n",
    "#         }\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         if self._is_eels:\n",
    "#             return len(self._pair_keys)\n",
    "#         else:\n",
    "#             return len(self._file['images'])\n",
    "\n",
    "# # ================== Lazy Loader Classes ==================\n",
    "# class ImageLazyLoader:\n",
    "#     def __init__(self, h5_file, group_name):\n",
    "#         self._h5_file = h5_file\n",
    "#         self._group = self._h5_file[group_name]\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self._group[f\"image_{index:04d}\"][:]\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self._group)\n",
    "\n",
    "# class MetadataLazyLoader(MetadataMethods):\n",
    "#     def __init__(self, h5_file):\n",
    "#         self._h5_file = h5_file\n",
    "#         self._group = self._h5_file['metadata']\n",
    "#         # Extract keys and sort by index\n",
    "#         self.keys = sorted(self._group.keys(), key=lambda x: int(x.split('_')[-1]))\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         if isinstance(index, int):\n",
    "#             key = self.keys[index]\n",
    "#         elif isinstance(index, str):\n",
    "#             key = index\n",
    "#         else:\n",
    "#             raise TypeError(\"Index must be int or str\")\n",
    "#         return json.loads(self._group[key].asstr()[()])\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self._group)\n",
    "    \n",
    "#     def _get_full_metadata(self):\n",
    "#         return [self[i] for i in range(len(self))]\n",
    "\n",
    "# class EELSLazyLoader(MetadataMethods):\n",
    "#     def __init__(self, h5_source, key=None):\n",
    "#         if isinstance(h5_source, str):\n",
    "#             self._h5_file = h5py.File(h5_source, 'r')\n",
    "#             self._needs_close = True\n",
    "#         else:\n",
    "#             self._h5_file = h5_source\n",
    "#             self._needs_close = False\n",
    "\n",
    "#         self._pair_keys = sorted(list(self._h5_file['pairs'].keys()))\n",
    "#         first_pair = self._h5_file['pairs'][self._pair_keys[0]]\n",
    "#         self._available_keys = list(first_pair.keys())\n",
    "\n",
    "#         # Create attributes for each available key\n",
    "#         for key_name in self._available_keys:\n",
    "#             setattr(self, key_name, self._create_lazy_accessor(key_name))\n",
    "\n",
    "#     def _create_lazy_accessor(self, key):\n",
    "#         class LazyAccessor:\n",
    "#             def __init__(self_inner, h5_file, pair_keys, key):\n",
    "#                 self_inner._h5_file = h5_file\n",
    "#                 self_inner._pair_keys = pair_keys\n",
    "#                 self_inner.key = key\n",
    "\n",
    "#             def __getitem__(self_inner, index):\n",
    "#                 group = self_inner._h5_file['pairs'][self_inner._pair_keys[index]]\n",
    "#                 dataset = group[self_inner.key]\n",
    "#                 if isinstance(dataset, h5py.Dataset) and dataset.dtype.kind in {'S', 'O'}:\n",
    "#                     return json.loads(dataset.asstr()[()])\n",
    "#                 return dataset[:]\n",
    "\n",
    "#             def __len__(self_inner):\n",
    "#                 return len(self_inner._pair_keys)\n",
    "                \n",
    "#             def _get_full_metadata(self_inner):\n",
    "#                 return [self_inner[i] for i in range(len(self_inner))]\n",
    "\n",
    "#         return LazyAccessor(self._h5_file, self._pair_keys, key)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # This is a fallback in case someone tries to index the main object\n",
    "#         # Normally you should access through the specific attributes\n",
    "#         group = self._h5_file['pairs'][self._pair_keys[index]]\n",
    "#         return {key: group[key][()] for key in self._available_keys}\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self._pair_keys)\n",
    "    \n",
    "#     def _get_full_metadata(self):\n",
    "#         return [self[i] for i in range(len(self))]\n",
    "                \n",
    "#     def close(self):\n",
    "#         if self._needs_close:\n",
    "#             self._h5_file.close()\n",
    "            \n",
    "#     def get_original_filenames(self, index):\n",
    "#         \"\"\"Get original filenames for a pair\"\"\"\n",
    "#         pair_group = self._h5_file['pairs'][self._pair_keys[index]]\n",
    "#         return {\n",
    "#             'point_spectrum': pair_group.attrs.get('point_spectrum_file', ''),\n",
    "#             'image': pair_group.attrs.get('image_file', '')\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4078df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import ImageSequence, EELSLazyLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ndata = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/081.ndata1'\n",
    "filepath_tiff = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/VCR stack (MAADF) cluster_2 14.11.tif'\n",
    "filepath_pkl = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/stack.pkl'\n",
    "metadata_pkl = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/metadata.pkl'\n",
    "filepath_h5 = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/stack.h5'\n",
    "filepath_eels = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/eels_point_spectrum_pairs.h5'\n",
    "stacks_ssb = ['/home/somar/Desktop/2025/Data for publication/Sample 2525/SSB reconstruction of 4d STEM data/stack_ssbs.h5']\n",
    "img = ImageSequence(stacks_ssb[0])\n",
    "data = img.raw_data\n",
    "metadata = img.raw_metadata\n",
    "print(f\"Number of images: {len(data)}\")\n",
    "print(metadata[0])\n",
    "fov = img.get_specific_metadata('timezone', data = metadata['metadata_0022'])\n",
    "fov\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ffed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Tiff data exmple\n",
    "h5_file = '/home/somar/Desktop/2025/Data for publication/Sample 2344/ADF images/'\n",
    "img = ImageSequence(filepath_h5)\n",
    "data = img.raw_data\n",
    "metadata = img.raw_metadata\n",
    "print(f\"Number of images: {len(data)}\")\n",
    "print(f\"Metadata for first image: {metadata[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b555d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading NDATA data example\n",
    "fp = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/SuperScan-MAADF_2025-02-26T153932.717062_2048x2048_0.ndata1'\n",
    "fp2 = '/home/somar/Desktop/own_stuff/cleaning script/sample data files/VCR stack (MAADF) cluster_2 14.11.ndata1'\n",
    "img = ImageSequence(fp2)\n",
    "data = img.raw_data\n",
    "metadata = img.raw_metadata\n",
    "print(f\"Number of images: {len(data)}\")\n",
    "i = 44\n",
    "print(data[i].shape, data[i])\n",
    "print(f\"Metadata: {metadata[0]}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading HDF5 data example. For h5 file format I choosed to index the metadata following this system: metadata_0001, metadata_0002, etc.\n",
    "img = ImageSequence(filepath_h5)\n",
    "data = img.raw_data\n",
    "metadata = img.raw_metadata\n",
    "print(f\"Number of images: {len(data)}\")\n",
    "print(f\"Metadata for first image: {metadata[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86093268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading EELS data example\n",
    "img = EELSLazyLoader(filepath_eels)\n",
    "data_image = img.image\n",
    "data_image_metadata = img.image_metadata\n",
    "data_spectrum = img.spectrum\n",
    "data_spectrum_metadata = img.spectrum_metadata\n",
    "data_filenames = img.get_original_filenames(0)\n",
    "print(f\"Number of pairs: {len(data_image)}\")\n",
    "print(f\"First image shape: {data_image[2].shape}\")\n",
    "print(f\"First spectrum shape: {len(data_spectrum[0])}\")\n",
    "print(f\"First image metadata: {data_image_metadata[0]}\")\n",
    "print(f\"First spectrum metadata: {data_spectrum_metadata[0]}\")\n",
    "print(f\"Original filenames for first pair: {data_filenames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfb7d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33753d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
