{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageanalysis.making_stacks import *\n",
    "dir1 = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/'\n",
    "dir2 = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2525/26-03-2025/'\n",
    "# process_directory_h5(dir1, output_file='different_sides.h5',sort_by='time')\n",
    "process_directory_h5(dir2, output_file='same_sides.h5',sort_by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "font_path = \"/home/somar/.fonts/SourceSansPro-Semibold.otf\" \n",
    " \n",
    "different_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/different_sides.h5'\n",
    "same_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2525/26-03-2025/same_sides.h5'\n",
    "\n",
    "from imageanalysis.image_processing import CalibratedImages\n",
    "calibrated_images = CalibratedImages(same_sides_irradiation, font_path=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "font_path = \"/home/somar/.fonts/SourceSansPro-Semibold.otf\" \n",
    "\n",
    "for_debugging_area = '/home/somar/Desktop/2025/Data for publication/Sample 2344/ADF images/2024-12-23_After_LaserCleaning_PtEvaporation/stack.h5'\n",
    "from imageanalysis.feature_analysis import FeaturesAnalysis\n",
    "features_analysis = FeaturesAnalysis(for_debugging_area, font_path=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "font_path = \"/home/somar/.fonts/SourceSansPro-Semibold.otf\" \n",
    "\n",
    "different_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2476/different_sides.h5'\n",
    "\n",
    "same_sides_irradiation = '/home/somar/Desktop/2025/Data for publication/Multilayer graphene/Sample 2525/26-03-2025/same_sides.h5'\n",
    "\n",
    "from imageanalysis.feature_analysis import FeaturesAnalysis\n",
    "\n",
    "features_analysis = FeaturesAnalysis(different_sides_irradiation, font_path=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf29d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "datafile = 'Sample_2476/cluster_density_analysis/2l_gr.csv'\n",
    "# datafile = 'Sample_2525/cluster_density_analysis/4l_gr.csv'\n",
    "# datafile = 'analysis_results.csv'\n",
    "datafile = 'Sample_2476/new_analysis/cda/kmeans_method/2L_gr.csv'\n",
    "df = pd.read_csv(datafile)\n",
    "# df['Roundness']\n",
    "# df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import norm, beta, gamma, lognorm, gaussian_kde\n",
    "def get_shape_metric_info(sh_metric):\n",
    "    \"\"\"Converts string-encoded list column into flat numeric list.\"\"\"\n",
    "    name = sh_metric.name\n",
    "    shape_metric = sh_metric.apply(ast.literal_eval)\n",
    "    values = list(chain.from_iterable(shape_metric))\n",
    "    return values, name\n",
    "\n",
    "def plot_shape_metric_distribution(sh_metric, name, n_layers=None, as_line=False):\n",
    "    \"\"\"Plot single shape metric as histogram or line curve.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if as_line:\n",
    "        counts, bins = np.histogram(sh_metric, bins=50)\n",
    "        centers = (bins[:-1] + bins[1:]) / 2\n",
    "        plt.plot(centers, counts, lw=2, color='blue')\n",
    "    else:\n",
    "        plt.hist(sh_metric, bins=50, density=True, alpha=0.8, color='blue')\n",
    "\n",
    "    title = f'{name.replace(\"_\", \" \").title()} Distribution'\n",
    "    if n_layers:\n",
    "        title += f' ({n_layers} Layers)'\n",
    "    plt.title(title)\n",
    "    plt.xlabel(name.replace(\"_\", \" \").title())\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_shape_metric_comparison(metric_list, n_layers=None, as_line=False, smooth=True, window_length=15, polyorder=5):\n",
    "    \"\"\"Plot histogram or smoothed line for multiple shape metrics.\"\"\"\n",
    "    fig, ax = plt.subplots(1, len(metric_list), figsize=(5 * len(metric_list), 5))\n",
    "    if len(metric_list) == 1:\n",
    "        ax = [ax]\n",
    "\n",
    "    for i, (sh_metric, name) in enumerate(metric_list):\n",
    "        counts, bins = np.histogram(sh_metric, bins=100, density=False)\n",
    "        centers = (bins[:-1] + bins[1:]) / 2\n",
    "        kde = gaussian_kde(sh_metric)\n",
    "        pdf = kde(centers)\n",
    "        factor = np.sum(counts * pdf) / np.sum(pdf ** 2)\n",
    "        pdf *= factor  # make the PDF to match histogram area\n",
    "        #  mean and std for Gaussian fit\n",
    "        dx = centers[1] - centers[0]\n",
    "        pdf_norm  = pdf / np.sum(pdf) / dx  # normalize to area=1\n",
    "        mean_pdf = np.sum(centers * pdf_norm) * dx\n",
    "        std_pdf = np.sqrt(np.sum((centers - mean_pdf) ** 2 * pdf_norm) * dx)\n",
    "        if as_line:\n",
    "            if smooth:\n",
    "                # Ensure window length is valid\n",
    "                wl = min(window_length, len(centers) - 1 if len(centers) % 2 == 0 else len(centers))\n",
    "                if wl % 2 == 0:\n",
    "                    wl -= 1\n",
    "                if wl >= 5:\n",
    "                    counts_smooth = savgol_filter(counts, window_length=wl, polyorder=polyorder)\n",
    "                else:\n",
    "                    counts_smooth = counts  # fallback if too short\n",
    "                ax[i].plot(centers, counts_smooth, lw=2, color='blue', label='Smoothed')\n",
    "            else:\n",
    "                ax[i].plot(centers, counts, lw=2, color='blue', label='Raw Line')\n",
    "        else:\n",
    "            ax[i].hist(sh_metric, bins=100, alpha=0.8, color='blue', label='Histogram')\n",
    "\n",
    "        # mu, std = norm.fit(sh_metric)\n",
    "        # gaussian = norm.pdf(centers, mu, std)\n",
    "        # factor = np.sum(counts * gaussian) / np.sum(gaussian **2)\n",
    "        # gaussian *= factor  \n",
    "\n",
    "\n",
    "        title = f'{name.replace(\"_\", \" \").title()}'\n",
    "        if n_layers:\n",
    "            title += f' ({n_layers} Layers)'\n",
    "        ax[i].plot(centers, pdf, 'r--', label=f'Gaussian Fit\\nμ = {mean_pdf:.4f}, σ = {std_pdf:.4f}')\n",
    "        ax[i].set_title(title)\n",
    "        ax[i].set_xlabel(name.replace(\"_\", \" \").title())\n",
    "        ax[i].set_ylabel('Density')\n",
    "        ax[i].legend()\n",
    "        ax[i].grid()\n",
    "\n",
    "    if n_layers:\n",
    "        plt.suptitle(f\"Shape Metrics Comparison for {n_layers} Layers\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_hist_with_gaussian_fit(data, label, bins=100, smooth=True):\n",
    "    data = np.array(data)\n",
    "    mu, std = norm.fit(data)\n",
    "\n",
    "    # Histogram\n",
    "    counts, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "    bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    if smooth:\n",
    "        y_fit = savgol_filter(counts, window_length=11, polyorder=3)\n",
    "    else:\n",
    "        y_fit = counts\n",
    "\n",
    "    # Gaussian curve for comparison\n",
    "    x_fit = np.linspace(min(data), max(data), 1000)\n",
    "    gaussian = norm.pdf(x_fit, mu, std)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(bin_centers, y_fit, label='Data (smoothed)', lw=2)\n",
    "    plt.plot(x_fit, gaussian, 'r--', label=f'Gaussian Fit\\nμ = {mu:.4f}, σ = {std:.4f}')\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel('Density')\n",
    "    plt.title(f'{label} Distribution with Gaussian Fit')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return mu, std\n",
    "\n",
    "\n",
    "# Main analysis\n",
    "datafile = 'Sample_2476/cluster_density_analysis/{}l_gr.csv'\n",
    "i = [2, 3, 4, 5]\n",
    "\n",
    "for number_of_layers in i:\n",
    "    df = pd.read_csv(datafile.format(number_of_layers))\n",
    "    \n",
    "    circularities, name1     = get_shape_metric_info(df['Circularities'])\n",
    "    feret_diameters, name2   = get_shape_metric_info(df['Feret_Diameter'])\n",
    "    aspect_ratios, name3     = get_shape_metric_info(df['Aspect_Ratio'])\n",
    "    clusters_area, name4     = get_shape_metric_info(df['Clusters'])\n",
    "    mean_circularity = np.array(circularities).mean()\n",
    "    mean_feret_diameter = np.array(feret_diameters).mean()\n",
    "    mean_aspect_ratio = np.array(aspect_ratios).mean()\n",
    "    mean_clusters_area = np.array(clusters_area).mean()\n",
    "    print(f\"Mean Circularity for {number_of_layers} layers: {mean_circularity:.4f}\")\n",
    "    print(f\"Mean Feret Diameter for {number_of_layers} layers: {mean_feret_diameter:.4f}\")\n",
    "    print(f\"Mean Aspect Ratio for {number_of_layers} layers: {mean_aspect_ratio:.4f}\")\n",
    "    print(f\"Mean Clusters Area for {number_of_layers} layers: {mean_clusters_area:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    plot_shape_metric_comparison([\n",
    "        (circularities, name1),\n",
    "        (feret_diameters, name2),\n",
    "        (aspect_ratios, name3),\n",
    "        (clusters_area, name4),\n",
    "    ], n_layers=number_of_layers, as_line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf85d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from imageanalysis.data_loader import DataLoader\n",
    "\n",
    "# -----------------------------\n",
    "# Load & crop your image\n",
    "# -----------------------------\n",
    "for_debugging_area = '/home/somar/Desktop/2025/Data for publication/Sample 2344/ADF images/2024-12-23_After_LaserCleaning_PtEvaporation/stack.h5'\n",
    "img = DataLoader(for_debugging_area)\n",
    "img = img[0]\n",
    "atom_img = img[97:97+100, 126:126+100] \n",
    "print(\"Crop shape:\", atom_img.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-Gaussian model\n",
    "# -----------------------------\n",
    "def multi_2D_Gaussian(coords, *params):\n",
    "    \"\"\"\n",
    "    Sum of n 2D Gaussians with a common offset.\n",
    "    params = [amp1, xo1, yo1, sigma_x1, sigma_y1, theta1,\n",
    "              amp2, xo2, yo2, sigma_x2, sigma_y2, theta2,\n",
    "              ...,\n",
    "              offset]\n",
    "    \"\"\"\n",
    "    x, y = coords\n",
    "    g = np.zeros_like(x, dtype=float)\n",
    "    n = (len(params)-1) // 6  # number of Gaussians\n",
    "    offset = params[-1]\n",
    "    \n",
    "    for i in range(n):\n",
    "        amp, xo, yo, sigma_x, sigma_y, theta = params[6*i:6*(i+1)]\n",
    "        xo = float(xo)\n",
    "        yo = float(yo)\n",
    "        a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)\n",
    "        b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)\n",
    "        c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)\n",
    "        g += amp * np.exp(-(a*((x-xo)**2) + 2*b*(x-xo)*(y-yo) + c*((y-yo)**2)))\n",
    "    \n",
    "    return (g + offset).ravel()\n",
    "\n",
    "# -----------------------------\n",
    "# Peak detection for initialization\n",
    "# -----------------------------\n",
    "def detect_peaks(img, threshold_rel=0.3, max_peaks=5):\n",
    "    \"\"\"\n",
    "    Detect approximate peak locations in an image.\n",
    "    \"\"\"\n",
    "    smooth = gaussian_filter(img, sigma=1)\n",
    "    local_max = (smooth == maximum_filter(smooth, size=5))\n",
    "    candidates = np.argwhere(local_max & (smooth > threshold_rel*smooth.max()))\n",
    "    \n",
    "    # Sort by intensity (strongest peaks first)\n",
    "    intensities = smooth[candidates[:,0], candidates[:,1]]\n",
    "    sorted_idx = np.argsort(intensities)[::-1]\n",
    "    candidates = candidates[sorted_idx]\n",
    "    \n",
    "    return candidates[:max_peaks]\n",
    "\n",
    "# -----------------------------\n",
    "# Fit function\n",
    "# -----------------------------\n",
    "def fit_atom_multi(atom_img, ngauss=3):\n",
    "    nrows, ncols = atom_img.shape\n",
    "    x = np.arange(0, ncols, 1)\n",
    "    y = np.arange(0, nrows, 1)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "    # --- detect peaks for initial guesses ---\n",
    "    peak_coords = detect_peaks(atom_img, threshold_rel=0.4, max_peaks=ngauss)\n",
    "    if len(peak_coords) < ngauss:\n",
    "        ngauss = len(peak_coords)\n",
    "\n",
    "    guess = []\n",
    "    bounds_lower, bounds_upper = [], []\n",
    "    for i, (yo, xo) in enumerate(peak_coords[:ngauss]):\n",
    "        amp_guess = atom_img.max() - atom_img.min()\n",
    "        sigma_guess = 2.0\n",
    "        theta_guess = 0.0\n",
    "        guess.extend([amp_guess, xo, yo, sigma_guess, sigma_guess, theta_guess])\n",
    "        \n",
    "        # Bounds for each Gaussian\n",
    "        bounds_lower.extend([0, 0, 0, 0.5, 0.5, -np.pi/4])\n",
    "        bounds_upper.extend([atom_img.max()*2, ncols, nrows, 10, 10, np.pi/4])\n",
    "\n",
    "    # background offset\n",
    "    guess.append(atom_img.min())\n",
    "    bounds_lower.append(0)\n",
    "    bounds_upper.append(atom_img.max()*2)\n",
    "\n",
    "    # --- curve fitting ---\n",
    "    popt, pcov = curve_fit(\n",
    "        multi_2D_Gaussian, (xv, yv), atom_img.ravel(),\n",
    "        p0=guess, bounds=(bounds_lower, bounds_upper),\n",
    "        maxfev=20000\n",
    "    )\n",
    "    return popt, (xv, yv), ngauss\n",
    "\n",
    "# -----------------------------\n",
    "# Example usage\n",
    "# -----------------------------\n",
    "popt, (xv, yv), ngauss = fit_atom_multi(atom_img, ngauss=3)\n",
    "\n",
    "# Build fitted image\n",
    "fit_img = multi_2D_Gaussian((xv, yv), *popt).reshape(atom_img.shape)\n",
    "\n",
    "# Integrated intensities per Gaussian\n",
    "for i in range(ngauss):\n",
    "    amp, xo, yo, sigma_x, sigma_y, theta = popt[6*i:6*(i+1)]\n",
    "    integ = 2*np.pi * amp * sigma_x * sigma_y\n",
    "    print(f\"Gaussian {i+1}: Integrated intensity = {integ:.2f}\")\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "axs[0].imshow(atom_img, cmap='inferno'); axs[0].set_title(\"Cropped atom\")\n",
    "axs[1].imshow(fit_img, cmap='inferno'); axs[1].set_title(\"Multi-Gaussian fit\")\n",
    "axs[2].imshow(atom_img-fit_img, cmap='bwr'); axs[2].set_title(\"Residual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "calibration = 0.007829  # nm/pixel\n",
    "\n",
    "# --- Gaussian fitting model ---\n",
    "def twoD_Gaussian(coords, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):\n",
    "    x, y = coords\n",
    "    xo = float(xo)\n",
    "    yo = float(yo)\n",
    "    a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)\n",
    "    b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)\n",
    "    c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)\n",
    "    g = offset + amplitude*np.exp(-(a*((x-xo)**2) + 2*b*(x-xo)*(y-yo) + c*((y-yo)**2)))\n",
    "    return g.ravel()\n",
    "\n",
    "def fit_atom(atom_img):\n",
    "    nrows, ncols = atom_img.shape\n",
    "    x = np.arange(0, ncols, 1)\n",
    "    y = np.arange(0, nrows, 1)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    initial_guess = (atom_img.max()-atom_img.min(), ncols/2, nrows/2, 2, 2, 0, atom_img.min())\n",
    "    popt, _ = curve_fit(twoD_Gaussian, (x, y), atom_img.ravel(), p0=initial_guess)\n",
    "    return popt\n",
    "\n",
    "\n",
    "params = fit_atom(atom_img)\n",
    "amp, xo, yo, sigma_x, sigma_y, theta, offset = params\n",
    "\n",
    "# --- Pixel-based area (simple threshold) ---\n",
    "_, mask = cv2.threshold(atom_img.astype(np.uint8), 0, 255, cv2.THRESH_OTSU)\n",
    "pixel_area = np.count_nonzero(mask) * (calibration**2)\n",
    "\n",
    "# --- Gaussian effective areas ---\n",
    "A_sigma = np.pi * sigma_x * sigma_y * (calibration**2)\n",
    "A_FWHM = np.pi * (1.178*sigma_x) * (1.178*sigma_y) * (calibration**2)\n",
    "\n",
    "print(f\"Pixel area (nm²): {pixel_area:.4f}\")\n",
    "print(f\"Gaussian 1σ ellipse area (nm²): {A_sigma:.4f}\")\n",
    "print(f\"Gaussian FWHM ellipse area (nm²): {A_FWHM:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEM single-atom / cluster quantification helpers\n",
    "# -------------------------------------------------\n",
    "# This cell defines READY-TO-USE functions to extract:\n",
    "# 1) Integrated HAADF cross-section (threshold-free)\n",
    "# 2) FWHM-based and α-isophote areas from Gaussian PSF fits\n",
    "# 3) Cluster fitting (sum of multiple Gaussians with shared sigma)\n",
    "#\n",
    "# Usage (quick start, once you have a cropped ROI \"roi\" around one atom):\n",
    "#   params = fit_single_gaussian(roi)\n",
    "#   out = summarize_fit(params, calib_nm_per_px=0.007829, alpha=0.5)\n",
    "#   print(out)\n",
    "#\n",
    "# For clusters:\n",
    "#   centers = find_peaks_2d(roi, min_distance=3, threshold_abs=roi.mean()+2*roi.std())\n",
    "#   params_cluster = fit_cluster_shared_sigma(roi, centers)\n",
    "#   report = summarize_cluster(roi, params_cluster, calib_nm_per_px=0.007829, alpha=0.5)\n",
    "#   print(report)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter\n",
    "\n",
    "# -----------------------------\n",
    "# 2D Gaussian building blocks\n",
    "# -----------------------------\n",
    "def gaussian2d_rotated(xy, amp, x0, y0, sx, sy, theta, offset):\n",
    "    \"\"\"\n",
    "    Single rotated 2D Gaussian + constant offset.\n",
    "    xy: (X, Y) meshgrid\n",
    "    amp: peak above offset (>=0)\n",
    "    (x0, y0): center (in pixels)\n",
    "    sx, sy: standard deviations (pixels, >0)\n",
    "    theta: rotation (radians)\n",
    "    offset: constant background\n",
    "    Returns raveled image.\n",
    "    \"\"\"\n",
    "    X, Y = xy\n",
    "    ct, st = np.cos(theta), np.sin(theta)\n",
    "    a = (ct**2)/(2*sx**2) + (st**2)/(2*sy**2)\n",
    "    b = -st*ct/(2*sx**2) + st*ct/(2*sy**2)\n",
    "    c = (st**2)/(2*sx**2) + (ct**2)/(2*sy**2)\n",
    "    return (offset + amp * np.exp(-(a*(X-x0)**2 + 2*b*(X-x0)*(Y-y0) + c*(Y-y0)**2))).ravel()\n",
    "\n",
    "def multi_gaussian2d_shared_sigma(xy, params, shared_theta=False):\n",
    "    \"\"\"\n",
    "    Sum of K Gaussians with shared (sx, sy) and shared offset.\n",
    "    params structure:\n",
    "        [sx, sy, offset,  amp1, x1, y1,  amp2, x2, y2,  ...]\n",
    "    If shared_theta=True, also passes a shared theta at the start:\n",
    "        [sx, sy, theta, offset,  amp1, x1, y1, ...]\n",
    "    \"\"\"\n",
    "    X, Y = xy\n",
    "    idx = 0\n",
    "    sx = params[idx]; idx+=1\n",
    "    sy = params[idx]; idx+=1\n",
    "    if shared_theta:\n",
    "        theta = params[idx]; idx+=1\n",
    "    else:\n",
    "        theta = 0.0\n",
    "    offset = params[idx]; idx+=1\n",
    "\n",
    "    img = np.zeros_like(X, dtype=float)\n",
    "    ct, st = np.cos(theta), np.sin(theta)\n",
    "    a = (ct**2)/(2*sx**2) + (st**2)/(2*sy**2)\n",
    "    b = -st*ct/(2*sx**2) + st*ct/(2*sy**2)\n",
    "    c = (st**2)/(2*sx**2) + (ct**2)/(2*sy**2)\n",
    "    while idx < len(params):\n",
    "        amp = params[idx]; x0 = params[idx+1]; y0 = params[idx+2]; idx += 3\n",
    "        img += amp * np.exp(-(a*(X-x0)**2 + 2*b*(X-x0)*(Y-y0) + c*(Y-y0)**2))\n",
    "    return (img + offset).ravel()\n",
    "\n",
    "# -----------------------------\n",
    "# Single-atom fitting (1 Gaussian)\n",
    "# -----------------------------\n",
    "def fit_single_gaussian(atom_img, sigma_init_px=2.0):\n",
    "    \"\"\"\n",
    "    Fit a single rotated 2D Gaussian + offset to a cropped ROI around one atom.\n",
    "    Returns fitted parameters: (amp, x0, y0, sx, sy, theta, offset)\n",
    "    \"\"\"\n",
    "    img = np.asarray(atom_img, dtype=float)\n",
    "    nrows, ncols = img.shape\n",
    "    y = np.arange(nrows); x = np.arange(ncols)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Initial guesses\n",
    "    amp0 = img.max() - img.min()\n",
    "    x0 = (ncols-1)/2\n",
    "    y0 = (nrows-1)/2\n",
    "    sx0 = sy0 = float(sigma_init_px)\n",
    "    theta0 = 0.0\n",
    "    offset0 = img.min()\n",
    "\n",
    "    p0 = (amp0, x0, y0, sx0, sy0, theta0, offset0)\n",
    "\n",
    "    # Bounds: enforce positive sigmas and reasonable centers\n",
    "    lower = (0,         0,         0,       0.3, 0.3, -np.pi/2, img.min()-abs(amp0))\n",
    "    upper = (np.inf, ncols-1, nrows-1,     10.0,10.0,  np.pi/2, img.max())\n",
    "\n",
    "    popt, pcov = curve_fit(gaussian2d_rotated, (X, Y), img.ravel(), p0=p0, bounds=(lower, upper), maxfev=20000)\n",
    "    return popt\n",
    "\n",
    "def summarize_fit(popt, calib_nm_per_px, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Given fitted single-Gaussian params and calibration (nm/px), compute:\n",
    "      - Integrated intensity (cross-section proxy): S = 2π * amp * sx * sy\n",
    "      - FWHM_x, FWHM_y (in nm)\n",
    "      - FWHM ellipse area (nm^2)\n",
    "      - alpha-isophote area (nm^2), where alpha in (0,1], default 0.5 (FWHM level for Gaussian)\n",
    "    \"\"\"\n",
    "    amp, x0, y0, sx, sy, theta, offset = popt\n",
    "    # Integrated intensity (model above background)\n",
    "    S = 2*np.pi * amp * sx * sy\n",
    "\n",
    "    # FWHM\n",
    "    f = 2*np.sqrt(2*np.log(2))\n",
    "    FWHM_x_nm = f * sx * calib_nm_per_px\n",
    "    FWHM_y_nm = f * sy * calib_nm_per_px\n",
    "\n",
    "    # FWHM ellipse area\n",
    "    A_FWHM_nm2 = (np.pi/4) * FWHM_x_nm * FWHM_y_nm\n",
    "\n",
    "    # alpha-isophote area: A_alpha(px^2)=2π sx sy ln(1/alpha) -> convert to nm^2\n",
    "    A_alpha_nm2 = (2*np.pi*sx*sy*np.log(1/alpha)) * (calib_nm_per_px**2)\n",
    "\n",
    "    return {\n",
    "        \"amp\": amp,\n",
    "        \"sigma_x_px\": sx,\n",
    "        \"sigma_y_px\": sy,\n",
    "        \"theta_rad\": theta,\n",
    "        \"offset\": offset,\n",
    "        \"Integrated_intensity_S\": S,\n",
    "        \"FWHM_x_nm\": FWHM_x_nm,\n",
    "        \"FWHM_y_nm\": FWHM_y_nm,\n",
    "        \"Area_FWHM_nm2\": A_FWHM_nm2,\n",
    "        f\"Area_alpha_{alpha:g}_nm2\": A_alpha_nm2,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Peak finding for clusters\n",
    "# -----------------------------\n",
    "def find_peaks_2d(img, min_distance=3, threshold_abs=None, footprint_size=3):\n",
    "    \"\"\"\n",
    "    Simple local-maximum finder using a maximum filter.\n",
    "    Returns a list of (y,x) peak coordinates.\n",
    "    \"\"\"\n",
    "    I = np.asarray(img, dtype=float)\n",
    "    if threshold_abs is None:\n",
    "        threshold_abs = I.mean() + 2*I.std()\n",
    "\n",
    "    # Smooth a bit to reduce noise peaks\n",
    "    Is = gaussian_filter(I, sigma=1.0)\n",
    "    # Local maxima\n",
    "    neighborhood = maximum_filter(Is, size=footprint_size)\n",
    "    peaks_mask = (Is == neighborhood) & (Is > threshold_abs)\n",
    "\n",
    "    ys, xs = np.nonzero(peaks_mask)\n",
    "\n",
    "    # Enforce min distance by greedy selection on intensity\n",
    "    vals = Is[ys, xs]\n",
    "    order = np.argsort(-vals)\n",
    "    selected = []\n",
    "    for idx in order:\n",
    "        y0, x0 = ys[idx], xs[idx]\n",
    "        if all((y0 - y1)**2 + (x0 - x1)**2 >= min_distance**2 for (y1, x1) in selected):\n",
    "            selected.append((y0, x0))\n",
    "    return selected\n",
    "\n",
    "# -----------------------------\n",
    "# Cluster fit: sum of Gaussians with shared sigma (PSF) & shared offset\n",
    "# -----------------------------\n",
    "def fit_cluster_shared_sigma(roi, centers_yx, sigma_init_px=2.0, shared_theta=False):\n",
    "    \"\"\"\n",
    "    Fit K Gaussians (K = len(centers_yx)) with shared (sx, sy) and offset.\n",
    "    centers_yx: list of (y,x) initial centers in pixel coords of roi.\n",
    "    Returns fitted params vector for multi_gaussian2d_shared_sigma.\n",
    "    \"\"\"\n",
    "    I = np.asarray(roi, dtype=float)\n",
    "    nrows, ncols = I.shape\n",
    "    y = np.arange(nrows); x = np.arange(ncols)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Initial params\n",
    "    sx0 = sy0 = float(sigma_init_px)\n",
    "    offset0 = float(np.percentile(I, 5))\n",
    "    amps0 = []\n",
    "    for (yy, xx) in centers_yx:\n",
    "        amps0 += [max(1e-3, I[int(yy), int(xx)] - offset0), float(xx), float(yy)]\n",
    "\n",
    "    if shared_theta:\n",
    "        p0 = [sx0, sy0, 0.0, offset0] + amps0\n",
    "        lower = [0.3, 0.3, -np.pi/2, np.min(I)-abs(np.ptp(I))] + [0, 0, 0]*(len(centers_yx))\n",
    "        upper = [10., 10.,  np.pi/2,  np.max(I)] + [np.inf, ncols-1, nrows-1]*(len(centers_yx))\n",
    "    else:\n",
    "        p0 = [sx0, sy0, offset0] + amps0\n",
    "        lower = [0.3, 0.3, np.min(I)-abs(np.ptp(I))] + [0, 0, 0]*(len(centers_yx))\n",
    "        upper = [10., 10., np.max(I)] + [np.inf, ncols-1, nrows-1]*(len(centers_yx))\n",
    "\n",
    "    popt, pcov = curve_fit(\n",
    "        lambda xy, *p: multi_gaussian2d_shared_sigma(xy, p, shared_theta=shared_theta),\n",
    "        (X, Y), I.ravel(), p0=p0, bounds=(lower, upper), maxfev=40000\n",
    "    )\n",
    "    return popt\n",
    "\n",
    "def summarize_cluster(roi, popt, calib_nm_per_px, alpha=0.5, shared_theta=False):\n",
    "    \"\"\"\n",
    "    From fitted cluster params, compute per-atom and total integrated intensities,\n",
    "    and a PSF-derived area metric (FWHM and alpha-isophote) using the shared sigma.\n",
    "    \"\"\"\n",
    "    idx = 0\n",
    "    sx = popt[idx]; idx+=1\n",
    "    sy = popt[idx]; idx+=1\n",
    "    if shared_theta:\n",
    "        theta = popt[idx]; idx+=1\n",
    "    else:\n",
    "        theta = 0.0\n",
    "    offset = popt[idx]; idx+=1\n",
    "\n",
    "    atoms = []\n",
    "    while idx < len(popt):\n",
    "        amp = popt[idx]; x0 = popt[idx+1]; y0 = popt[idx+2]; idx += 3\n",
    "        S = 2*np.pi * amp * sx * sy               # integrated intensity of this Gaussian\n",
    "        atoms.append({\"amp\": amp, \"x0_px\": x0, \"y0_px\": y0, \"S\": S})\n",
    "\n",
    "    # Shared PSF areas\n",
    "    f = 2*np.sqrt(2*np.log(2))\n",
    "    FWHM_x_nm = f * sx * calib_nm_per_px\n",
    "    FWHM_y_nm = f * sy * calib_nm_per_px\n",
    "    A_FWHM_nm2 = (np.pi/4) * FWHM_x_nm * FWHM_y_nm\n",
    "    A_alpha_nm2 = (2*np.pi*sx*sy*np.log(1/alpha)) * (calib_nm_per_px**2)\n",
    "\n",
    "    total_S = sum(a[\"S\"] for a in atoms)\n",
    "    report = {\n",
    "        \"shared_sigma_x_px\": sx,\n",
    "        \"shared_sigma_y_px\": sy,\n",
    "        \"shared_theta_rad\": theta,\n",
    "        \"offset\": offset,\n",
    "        \"per_atom\": atoms,\n",
    "        \"total_integrated_intensity_S\": total_S,\n",
    "        \"FWHM_x_nm\": FWHM_x_nm,\n",
    "        \"FWHM_y_nm\": FWHM_y_nm,\n",
    "        \"Area_FWHM_nm2\": A_FWHM_nm2,\n",
    "        f\"Area_alpha_{alpha:g}_nm2\": A_alpha_nm2,\n",
    "    }\n",
    "    return report\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Helper to build ROI around a given center with padding\n",
    "# -----------------------------\n",
    "def crop_centered(img, center_yx, half_size):\n",
    "    y0, x0 = center_yx\n",
    "    y0, x0 = int(round(y0)), int(round(x0))\n",
    "    y1, y2 = y0-half_size, y0+half_size+1\n",
    "    x1, x2 = x0-half_size, x0+half_size+1\n",
    "    y1 = max(0, y1); x1 = max(0, x1)\n",
    "    y2 = min(img.shape[0], y2); x2 = min(img.shape[1], x2)\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "# -----------------------------\n",
    "# Minimal demo on synthetic data (so you see outputs now):\n",
    "# -----------------------------\n",
    "\n",
    "# Synthetic single atom\n",
    "nx, ny = 41, 41\n",
    "y = np.arange(ny); x = np.arange(nx)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "img_syn = gaussian2d_rotated((X, Y), amp=200, x0=20, y0=21, sx=2.5, sy=2.0, theta=0.0, offset=10).reshape(ny, nx)\n",
    "# Fit\n",
    "p_single = fit_single_gaussian(atom_img)\n",
    "out_single = summarize_fit(p_single, calib_nm_per_px=0.007829, alpha=0.5)\n",
    "out_single\n",
    "\n",
    "# # Synthetic cluster of 3 atoms with shared sigma\n",
    "# img_clu = (\n",
    "#     gaussian2d_rotated((X, Y), 180, 10, 20, 2.2, 2.0, 0.0, 0) +\n",
    "#     gaussian2d_rotated((X, Y), 120, 22, 18, 2.2, 2.0, 0.0, 0) +\n",
    "#     gaussian2d_rotated((X, Y),  90, 29, 26, 2.2, 2.0, 0.0, 0) + 15\n",
    "# ).reshape(ny, nx)\n",
    "\n",
    "# centers = find_peaks_2d(img_clu, min_distance=4, threshold_abs=img_clu.mean()+2*img_clu.std())\n",
    "# p_cluster = fit_cluster_shared_sigma(img_clu, centers, sigma_init_px=2.0, shared_theta=False)\n",
    "# rep = summarize_cluster(img_clu, p_cluster, calib_nm_per_px=0.007829, alpha=0.5, shared_theta=False)\n",
    "# print(\"Cluster (synthetic) summary:\", rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c31486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi is your 2D numpy array around a single Pt atom (e.g., 25×25 px)\n",
    "calib = 0.007829  # nm/pixel\n",
    "\n",
    "popt = fit_single_gaussian(atom_img)                     # fit 1 Gaussian + offset\n",
    "summary = summarize_fit(popt, calib_nm_per_px=calib, alpha=0.5)\n",
    "\n",
    "summary\n",
    "# Keys:\n",
    "#  - Integrated_intensity_S        (cross-section proxy, threshold-free)\n",
    "#  - FWHM_x_nm, FWHM_y_nm\n",
    "#  - Area_FWHM_nm2\n",
    "#  - Area_alpha_0.5_nm2            (α can be changed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
